---
title: "Sleep, relative to wake, increases both veridical and false memory in the DRM paradigm: 
A registered report"
author: "Matthew H.C. Mak, Alice O’Hagan, Aidan J. Horner, M. Gareth Gaskell"
date: "Department of Psychology, University of York, UK"
output:
   bookdown::pdf_document2:
    keep_tex: true
    toc: false
    fig_caption: yes
header-includes:
  # - \usepackage{setspace}\doublespacing
  \usepackage{caption}
  \usepackage{float} \floatplacement{figure}{H} 
  \newcommand{\beginsupplement}{\setcounter{table}{0}     
  \renewcommand{\thetable}{D\arabic{table}} \setcounter{figure}{0} 
  \renewcommand{\thefigure}{D\arabic{figure}}}  
bibliography: references.bib
link-citations: true
linkcolor: black
csl: proceedings-of-the-royal-society-b.csl
---

```{r setup, include=FALSE}

processdata <- 0   # running all analyses from scratch takes about 6 hours
buildfigures <- 0

packagelist <- c('bookdown','knitr','rmarkdown','osfr','plyr','tidyr','dplyr','emmeans','ggplot2','Rmisc','buildmer','lme4','lmerTest','stringr','effects','effectsize','ggdist','car','gridExtra','kableExtra','rstatix','LSAfun','simr','effsize','readr')
missingpackages <- packagelist[!packagelist %in% installed.packages()[,1]]
if (length(missingpackages)>0){install.packages(missingpackages)}
toinstall <- packagelist[which(!packagelist %in% (.packages()))]
invisible(lapply(toinstall,library,character.only=TRUE))

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

```

``` {r getdata}

if (!dir.exists('data')){dir.create('data')}
if (!dir.exists('Figures')){dir.create('Figures')}

# download the data if not already present
osfproject <- osf_retrieve_node("9pdyf")
osffiles <- osf_ls_files(osfproject,path='Stage 2/Data/All the csv needed for Final_Analysis.Rmd')
if (!file.exists('data/full.csv')){
  hid <- pmatch('full.csv',as.character(unlist(osffiles[,1])))
  osf_download(osffiles[hid,], path='data/')
}
if (!file.exists('data/lure_final.csv')){
  hid <- pmatch('lure_final.csv',as.character(unlist(osffiles[,1])))
  osf_download(osffiles[hid,], path='data/')
}
if (!file.exists('data/studied_final.csv')){
  hid <- pmatch('studied_final.csv',as.character(unlist(osffiles[,1])))
  osf_download(osffiles[hid,], path='data/')
}
if (!file.exists('data/Table 2_Material.csv')){
  hid <- pmatch('Table 2_Material.csv',as.character(unlist(osffiles[,1])))
  osf_download(osffiles[hid,], path='data/')
}

lure <- read.csv('data/lure_final.csv')
studied <- read.csv('data/studied_final.csv') 
raw_fm <- read.csv('data/full.csv')
material <- read.csv('data/Table 2_Material.csv')

if (processdata==0){load('data/processeddata.RData')}

```

```{r changelabels}
lure$Delay <- str_replace_all(lure$Delay, "control", "Immediate/Control")
lure$Delay <- str_replace_all(lure$Delay, "delay", "12-hour delay")
lure$Delay <- factor(lure$Delay, levels = c("Immediate/Control","12-hour delay"))

studied$Delay <- str_replace_all(studied$Delay, "control", "Immediate/Control")
studied$Delay <- str_replace_all(studied$Delay, "delay", "12-hour delay")
studied$Delay <- factor(studied$Delay, levels = c("Immediate/Control","12-hour delay"))

intrusions <- distinct(lure, Participant.Private.ID, .keep_all = T)
intrusions$answer <- NULL
intrusions$original_response <- NULL
intrusions$lure_recalled <- NULL
```

```{r poissonregression}

if (processdata==0){
intrusion_poisson <- glm(intrusions ~ Delay*Test.Time, data = intrusions, family = poisson(link = "log"))

int_pois_sum <- summary(intrusion_poisson)

intrusionout <- emmeans(intrusion_poisson, pairwise ~ Test.Time | Delay)
#Test time (PM>AM) showed a large effect on output bias

int_sum <- summary(intrusionout)

}

```

```{r makeintrusiongraph}

intrusion_CI <- summarySE(data = intrusions, measurevar = "intrusions", groupvars = c("Delay", "Test.Time"), conf.interval = 0.95)

if (buildfigures==1){
pdf('Figures/intrusiongraph.pdf',width=15,height=10)

plothandle <- ggplot(intrusions%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")) ,
       aes(Test.Time, intrusions, fill=Test.Time))+
  ggdist::stat_halfeye(adjust = .9, width = .7, .width = 0, justification = -.2, point_colour = NA, alpha=0.5) + 
  stat_summary(fun=mean, geom = "bar", width=0.3)+
  labs(y="Number of Intrusions", x="", title="Intrusion", size=30)+
  geom_errorbar(width=.1, aes(ymin=intrusions-ci, ymax=intrusions+ci), position = position_dodge(width = 0.2), data=intrusion_CI%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")))+
  scale_y_continuous(expand = c(0,0),limits = c(0,60),breaks=seq(0,60,5))+
  theme_light()+
  theme(legend.position="none",legend.title = element_blank(), axis.title.y = element_text(size=16),plot.title = element_text(size=25, face="bold"), axis.text.x = element_text(size=16),axis.text.y = element_text(size=25),legend.text = element_text(size=25), axis.title=element_text(size=25,face="bold"),strip.text = element_text(size = 25), aspect.ratio =1/1)+ scale_fill_manual(values = c("darkorange", "cornflowerblue", "darkorange", "cornflowerblue" ))+coord_cartesian(ylim = c(0,60))+facet_wrap(~Delay,scales = "free_x")+ geom_dotplot(binaxis = "y", stackdir = "down",dotsize = 0.25)

grid.arrange(plothandle, ncol=1)

invisible(dev.off())
}

```

```{r lurecontrast}
lure$Delay <- as.factor(lure$Delay)
contrasts(lure$Delay) <- contr.sum(2)   
lure$Test.Time <- as.factor(lure$Test.Time)
contrasts(lure$Test.Time) <- contr.sum(2)
```

```{r lureGLM}

if (processdata==1){
lure_model_buildmer <- buildmer(lure_recalled ~ Delay * Test.Time +intrusions +
                                       (intrusions | Participant.Private.ID) + 
                                       (Delay * Test.Time| answer), 
                                     data = lure, 
                                     family = "binomial",
                                     buildmerControl = buildmerControl(direction='backward',args =list(control=glmerControl(optimizer="bobyqa"))))

lure_model <- glmer(formula(lure_model_buildmer), data = lure, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa')) 

# pre-registered pair-wise comparison
lure_pairwise <- emmeans(lure_model, pairwise ~ Test.Time | Delay)

# exploratory analysis to obtain an effect size for the effect of sleep
lureeffects <- eff_size(lure_pairwise, sigma(lure_model), edf = Inf) 
}


```

```{r lureGLMnointrusions}
if (processdata==1){
lure_model_without_covariate_buildmer <- buildmer(lure_recalled ~ Delay * Test.Time +
                                       (1 | Participant.Private.ID) + 
                                       (Delay * Test.Time| answer), 
                                     data = lure, 
                                     family = "binomial",
                                     buildmerControl = buildmerControl(direction='backward',args =list(control=glmerControl(optimizer="bobyqa"))))
}

```

```{r lureBayesian}

if (processdata==1){
null_lure <- update(lure_model, formula = ~ . -Delay*Test.Time)

#Bayes Factor
lureBF <- exp((BIC(null_lure)-BIC(lure_model))/2)
}

```

```{r lureBayesianSE}

if (processdata==1){
#simple effects of test time
lure_immediate <- subset(lure, Delay=="Immediate/Control")

lure_delay <- subset(lure, Delay=="12-hour delay")

#delay
lure_delay_model1 <- buildmer(lure_recalled ~ Test.Time +intrusions + (intrusions | Participant.Private.ID) + (Test.Time| answer), data = lure_delay, family = "binomial", buildmerControl = buildmerControl(direction='backward',args = list(control=glmerControl(optimizer="bobyqa"))))

lure_delay_model1_null <- update(lure_delay_model1, formula = ~ . -Test.Time)

luredelayBF <- exp(BIC(lure_delay_model1_null)-BIC(lure_delay_model1))/2 #= 0.001937424


#immediate
lure_immediate_model1 <- buildmer(lure_recalled ~ Test.Time +intrusions +
                                       (intrusions | Participant.Private.ID) + 
                                       (Test.Time| answer), 
                                     data = lure_immediate, 
                                     family = "binomial",
                                     buildmerControl = buildmerControl(direction='backward',args =list(control=glmerControl(optimizer="bobyqa"))))

lure_immediate_model1_null <- update(lure_immediate_model1, formula = ~ . -Test.Time)

lureimmediateBF <- exp(BIC(lure_immediate_model1_null)-BIC(lure_immediate_model1))/2 #= 0.0001069749
}


```

```{r lureposcontrol}

lure_pp <- ddply(lure, .(Delay, Test.Time, Participant.Private.ID), summarise, Lure.Recalled=sum(lure_recalled))

if (processdata==1){

#one sample t-test
lurettest <- t.test(lure_pp$Lure.Recalled, mu=0) #t = 26.964, df = 487, p-value < 2.2e-16

}

```

```{r makeluregraph}
#confidence interval for graph
lure_CI <- Rmisc::summarySE(lure_pp, measurevar = "Lure.Recalled", groupvars = c("Delay", "Test.Time"), conf.interval = 0.95)

if (buildfigures==1){
pdf('Figures/luregraph.pdf',width=15,height=10)

plothandle <- ggplot(lure_pp%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")) ,
       aes(Test.Time, Lure.Recalled, fill=Test.Time))+
  ggdist::stat_halfeye(adjust = .9, width = .7, .width = 0, justification = -.2, point_colour = NA, alpha=0.5) + 
  stat_summary(fun=mean, geom = "bar", width=0.3)+
  labs(y="Number of Lures Falsely Recalled (Max = 20)", x="", title="Lure", size=30)+
  geom_errorbar(width=.1, aes(ymin=Lure.Recalled-ci, ymax=Lure.Recalled+ci), position = position_dodge(width = 0.2), data=lure_CI%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")))+
  scale_y_continuous(expand = c(0,0),limits = c(-0.1,15.5),breaks=seq(0,15,2))+
  theme_light()+
  theme(legend.position="none",legend.title = element_blank(), axis.title.y = element_text(size=16),plot.title = element_text(size=25, face="bold"), axis.text.x = element_text(size=16),axis.text.y = element_text(size=25),legend.text = element_text(size=25), axis.title=element_text(size=25,face="bold"),strip.text = element_text(size = 25), aspect.ratio =1/1)+ scale_fill_manual(values = c("darkorange", "cornflowerblue", "darkorange", "cornflowerblue" ))+coord_cartesian(ylim = c(-0.1,15.1))+facet_wrap(~Delay,scales = "free_x")+ geom_dotplot(binaxis = "y", stackdir = "down",dotsize = 0.25)

grid.arrange(plothandle, ncol=1)

invisible(dev.off())
}

```

```{r studiededits}

studied$Delay <- as.factor(studied$Delay)
contrasts(studied$Delay) <- contr.sum(2)   
studied$Test.Time <- as.factor(studied$Test.Time)
contrasts(studied$Test.Time) <- contr.sum(2)

```

```{r studiedGLM}

if (processdata==1){
studied_model_buildmer <- buildmer(studied_recalled ~ Delay * Test.Time +intrusions + (intrusions | Participant.Private.ID) + (Delay * Test.Time| answer), data = studied, family = "binomial",buildmerControl = buildmerControl(direction='backward', args = list(control=glmerControl(optimizer="bobyqa"))))

studied_model <- glmer(formula(studied_model_buildmer), data = studied, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))

# studied_model <- glmer(formula(studied_model_buildmer), data = studied, family = binomial(link = 'logit'), nAGQ=0, control = glmerControl(optimizer = 'nloptwrap'))

studiedem1 <- emmeans(studied_model, pairwise ~ Test.Time | Delay)
studiedem2 <- emmeans(studied_model, pairwise ~ Delay | Test.Time)
}


```

```{r studiedBF}
if (processdata==1){
null_studied <- update(studied_model, formula = ~ . -Delay*Test.Time)

#Bayes Factor
studiedBF <- exp((BIC(null_studied)-BIC(studied_model))/2) #29122036
}

```

```{r studiedBayesian}

#simple effects of test time
studied_immediate <- subset(studied, Delay=="Immediate/Control")
studied_delay <- subset(studied, Delay=="12-hour delay")

studied_impp <- ddply(studied_immediate, .(Participant.Private.ID), summarise, Studied.Recalled=sum(studied_recalled))
studied_delpp <- ddply(studied_delay, .(Participant.Private.ID), summarise, Studied.Recalled=sum(studied_recalled))

if (processdata==1){

#delay
studied_delay_model1 <- buildmer(studied_recalled ~ Test.Time +intrusions +
                                       (intrusions | Participant.Private.ID) + 
                                       (Test.Time| answer), 
                                     data = studied_delay, 
                                     family = "binomial",
                                     buildmerControl = buildmerControl(direction='backward',args =list(control=glmerControl(optimizer="bobyqa"))))


studied_delay_model1_null <- update(studied_delay_model1, formula = ~ . -Test.Time)

studdelayBF <- exp(BIC(studied_delay_model1_null)-BIC(studied_delay_model1))/2 #0.01763277

#immediate
studied_immediate_model1 <- buildmer(studied_recalled ~ Test.Time +intrusions +
                                       (intrusions | Participant.Private.ID) + 
                                       (Test.Time| answer), 
                                     data = studied_immediate, 
                                     family = "binomial",
                                     buildmerControl = buildmerControl(direction='backward',args =list(control=glmerControl(optimizer="bobyqa"))))


studied_immediate_model1_null <- update(studied_immediate_model1, formula = ~ . -Test.Time)

studimBF <- exp(BIC(studied_immediate_model1_null)-BIC(studied_immediate_model1))/2 #0.0003863469

}
```

```{r makestudiedgraph}

studied_pp <- ddply(studied, .(Delay, Test.Time, Participant.Private.ID), summarise, Studied.Recalled=sum(studied_recalled))
studied_CI <- Rmisc::summarySE(data = studied_pp, measurevar = "Studied.Recalled", groupvars = c("Delay", "Test.Time"), conf.interval = 0.95)

if (buildfigures==1){

pdf('Figures/studiedgraph.pdf',width=15,height=10)

plothandle <- ggplot(studied_pp%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")) ,
       aes(Test.Time, Studied.Recalled, fill=Test.Time))+
  ggdist::stat_halfeye(adjust = .9, width = .7, .width = 0, justification = -.2, point_colour = NA, alpha=0.5) + 
  stat_summary(fun=mean, geom = "bar", width=0.3)+
  labs(y="Number of Studied Words Recalled (Max = 160)", x="", title="Studied", size=30)+
  geom_errorbar(width=.1, aes(ymin=Studied.Recalled-ci, ymax=Studied.Recalled+ci), position = position_dodge(width = 0.2), data=studied_CI%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")))+
  scale_y_continuous(expand = c(0,0),limits = c(0,110),breaks=seq(0,110,10))+
  theme_light()+
  theme(legend.position="none",legend.title = element_blank(), axis.title.y = element_text(size=16),plot.title = element_text(size=25, face="bold"), axis.text.x = element_text(size=16),axis.text.y = element_text(size=25),legend.text = element_text(size=25), axis.title=element_text(size=25,face="bold"),strip.text = element_text(size = 25), aspect.ratio =1/1)+ scale_fill_manual(values = c("darkorange", "cornflowerblue", "darkorange", "cornflowerblue" ))+coord_cartesian(ylim = c(0,110))+facet_wrap(~Delay,scales = "free_x")+ geom_dotplot(binaxis = "y", stackdir = "down",dotsize = 0.25)

grid.arrange(plothandle, ncol=1)

invisible(dev.off())

}

```

```{r excludeparticipants, include=FALSE}

raw_fm <- raw_fm %>% separate(Experiment.ID, c("Delay", "Test.Time")) 

fm <- subset(raw_fm,  subset = !Participant.Private.ID %in% c(7862197,
7636967,
7733905,
7643108,
7848363,
8307220,
8280100,
8401290,
8354767,
8209020,
7674684,
7814523,
7954183,
8138170,
8246649,
8393638,
7968031,
7806505,
8137770,
8116661,
8190616,
7655503,
7818063,
7999266,
8200792,
8225383,
8394785,
7817900,
7839745,
8201245,
8192060,
7941696,
7657171,
8201078,
8141329,
7676682,
8007863,
8021105,
7649898,
8171977,
8345258,
8061284,
8196008,
8471724,
8511638,
8474922,
8474259))

fm2 <- fm
fm2$response[fm2$response == ""] <- NA

fm2$filled <- ifelse(is.na(fm2$response), 0, 1)

total <- ddply(fm2, .(Participant.Private.ID, Delay, Test.Time), summarise, total=sum(filled))

# total response per group (Mean and SD)
totalstats <- ddply(total, .(Delay, Test.Time), summarise, average=mean(total), stdev=sd(total))

# ANOVA
total_anova <- aov(log10(total) ~ Delay*Test.Time, data = total)
total_resid <- car::qqPlot(total_anova$residuals, id = FALSE) #looks great

```

```{r maketotalgraph}

total$Delay <- str_replace_all(total$Delay, "control", "Immediate/Control")
total$Delay <- str_replace_all(total$Delay, "delay", "12-hour delay")
total$Delay <- factor(total$Delay, levels = c("Immediate/Control","12-hour delay"))

total_CI <- Rmisc::summarySE(data = total, measurevar = "total", groupvars = c("Delay", "Test.Time"), conf.interval = 0.95)

if (buildfigures==1){

pdf('Figures/totalgraph.pdf',width=15,height=10)

plothandle <- ggplot(total%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")),
       aes(Test.Time, total, fill=Test.Time))+
  ggdist::stat_halfeye(adjust = .9, width = .7, .width = 0, justification = -.2, point_colour = NA, alpha=0.5) + 
  stat_summary(fun=mean, geom = "bar", width=0.3)+
  labs(y="Number of responses", x="", title="Total responses", size=30)+
  scale_y_continuous(expand = c(0,0),limits = c(0,150),breaks=seq(0,150,20))+
  theme_light()+
  theme(legend.position="none",legend.title = element_blank(), axis.title.y = element_text(size=16),plot.title = element_text(size=25, face="bold"), axis.text.x = element_text(size=16),axis.text.y = element_text(size=25),legend.text = element_text(size=25), axis.title=element_text(size=25,face="bold"),strip.text = element_text(size = 25), aspect.ratio =1/1)+ scale_fill_manual(values = c("darkorange", "cornflowerblue", "darkorange", "cornflowerblue" ))+coord_cartesian(ylim = c(0,150))+facet_wrap(~Delay,scales = "free_x")+ geom_dotplot(binaxis = "y", stackdir = "down",dotsize = 0.25)+
  geom_errorbar(width=.1, aes(ymin=total-ci, ymax=total+ci), position = position_dodge(width = 0.2), data=total_CI%>%
         mutate(Test.Time = case_when(Delay=="Immediate/Control"~Test.Time,
                       Test.Time== "AM" ~ "Sleep",
                       TRUE ~ "Wake")))

grid.arrange(plothandle, ncol=1)

invisible(dev.off())

}
```

```{r recalleffect, include=FALSE}

#just some merging for easier manipulation
studied_pp2 <- select(studied_pp, Participant.Private.ID, Studied.Recalled)
intrusions2 <- select(intrusions, Participant.Private.ID, intrusions)
lure_pp_explore <- left_join(lure_pp, studied_pp2, by="Participant.Private.ID")
lure_pp_explore <- left_join(lure_pp_explore, intrusions2,by="Participant.Private.ID")
lure_pp_explore_delay <- subset(lure_pp_explore, Delay=="12-hour delay")

#obtain adjusted recall (correct recall - intrusion)
lure_pp_explore_delay$adjusted_recall <- lure_pp_explore_delay$Studied.Recalled-lure_pp_explore_delay$intrusions
median(lure_pp_explore_delay$adjusted_recall) # adjusted recall median = 5
lure_pp_explore_delay$adjusted_recall_binary <- lure_pp_explore_delay$adjusted_recall
lure_pp_explore_delay$adjusted_recall_binary <- ifelse(lure_pp_explore_delay$adjusted_recall_binary>5, "High performer", "Low performer")

premmeans <- ddply(lure_pp_explore_delay, .(Test.Time,adjusted_recall_binary), summarise, average=mean(Lure.Recalled), stdev=sd(Lure.Recalled))

#poisson regression
prsum <- summary(lure_explore <- glm(Lure.Recalled ~ Test.Time*adjusted_recall_binary, data = lure_pp_explore_delay, family = poisson(link = "log")))

prem <- emmeans(lure_explore, pairwise ~ Test.Time | adjusted_recall_binary)

#graph (not reported in manuscript)
#lure_pp_explore_delay$Test.Time <- str_replace_all(lure_pp_explore_delay$Test.Time, "AM", "Sleep")
#lure_pp_explore_delay$Test.Time <- str_replace_all(lure_pp_explore_delay$Test.Time, "PM", "Wake")
#ggplot(lure_pp_explore_delay, aes(Test.Time,Lure.Recalled, fill=Test.Time))+stat_summary(fun=mean, geom = "bar")+  stat_summary(fun=mean, geom = "bar", width=0.01,position =position_dodge(width=.01))+scale_y_continuous(expand = c(0,0),limits = c(0,20),breaks=seq(0,20,2))+theme_light()+theme(legend.position="none",legend.title = element_blank(), axis.title.y = element_text(size=16),plot.title = element_text(size=25, face="bold"), axis.text.x = element_text(size=16),axis.text.y = element_text(size=25),legend.text = element_text(size=25), axis.title=element_text(size=25,face="bold"),strip.text = element_text(size = 25), aspect.ratio =1/1)+ scale_fill_manual(values = c("darkorange", "cornflowerblue"))+coord_cartesian(ylim = c(0,20))+ geom_dotplot(binaxis = "y", stackdir = "down",dotsize = 0.25)+facet_wrap(~adjusted_recall_binary)

``` 

```{r dependency}

studied2 <- studied

studied2 <- left_join(studied2, material, by="answer")

studied2_by_lure <- ddply(studied2, .(Participant.Private.ID, lure), summarise, N_per_list = sum(studied_recalled))

lure2 <- lure

lure2 <- rename(lure2, lure = answer)

lure2 <- select(lure2, Participant.Private.ID, Delay, Test.Time, lure, lure_recalled, intrusions)

iota_explore <- left_join(studied2_by_lure, lure2, by=c("Participant.Private.ID", "lure"))

#delay only
iota_explore_delay <- subset(iota_explore, Delay=="12-hour delay")

#wake group only
iota_explore_delay_wake <- subset(iota_explore_delay, Test.Time=="PM")

#sleep group only
iota_explore_delay_sleep <- subset(iota_explore_delay, Test.Time=="AM")

```

```{r allgroups}

if (processdata==1){
  
iota_buildmer000 <- buildmer(lure_recalled ~ Delay*Test.Time*N_per_list+ intrusions + (N_per_list+ intrusions | Participant.Private.ID) + (Test.Time| lure), data = iota_explore, family = "binomial", buildmerControl = buildmerControl(direction='backward', args = list(control=glmerControl(optimizer="bobyqa"))))

}

#Given the significant Delay1:Test.Time1:N_per_list, we looked at the Immediate and Delay groups separately below
```

```{r delaygroup}

if (processdata){
  
iota_buildmer2 <- buildmer(lure_recalled ~ Test.Time*N_per_list+ intrusions +
(N_per_list+ intrusions | Participant.Private.ID) + (Test.Time| lure), data = iota_explore_delay, family = "binomial",buildmerControl = buildmerControl(direction='backward',args = list(control=glmerControl(optimizer="bobyqa"))))

iota_buildmer2_standard <- glmer(formula(iota_buildmer2), data = iota_explore_delay, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))

}

```

```{r immediategroup}

if (processdata){
  
iota_explore_immediate <- subset(iota_explore, Delay=="Immediate/Control")

iota_buildmer3_standard <- glmer(lure_recalled ~ Test.Time * N_per_list + intrusions + (1 | Participant.Private.ID) + (1| lure), data = iota_explore_immediate, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))

save(file='data/processeddata.RData',list=c('intrusion_poisson','intrusionout','intrusion_CI','lure_model_buildmer','lure_model','lure_pairwise','lureeffects','lure_model_without_covariate_buildmer','null_lure','lureBF','lure_delay_model1','lure_immediate_model1','lure_delay_model1_null','lure_immediate_model1_null','luredelayBF','lureimmediateBF','lurettest','studied_model_buildmer','studied_model','studiedem1','studiedem2','studiedBF','studied_delay_model1','studied_delay_model1_null','studdelayBF','studied_immediate_model1','studied_immediate_model1_null','studimBF','prem','prsum','iota_buildmer000','iota_buildmer2','iota_buildmer2_standard','iota_buildmer3_standard'))

}

```

```{r makedelaygraph}

eff.p1 <- effect("Test.Time:N_per_list", iota_buildmer2_standard, KR=T)
eff.p1 <- as.data.frame(eff.p1)
eff.p1$Test.Time <- ifelse(eff.p1$Test.Time=="AM", "Sleep", "Wake")

probabilities <- ddply(iota_explore_delay, .(Participant.Private.ID, Test.Time), summarise, N_per_list_mean=mean(N_per_list), lure_mean=mean(lure_recalled))


if (buildfigures==1){
  
pdf('Figures/delaygraph.pdf',width=18,height=9)

plot1 <- ggplot(eff.p1, aes(N_per_list, color = Test.Time)) +
  geom_line(aes(y = fit, group=factor(Test.Time)), size=1.2) +
  geom_line(aes(y = lower,
                group=factor(Test.Time)), linetype =3) +
  geom_line(aes(y = upper,
                group=factor(Test.Time)), linetype =3) +
  xlab("Correct recall per list (Max = 8)") +
  ylab("Lure recall probability") +
  scale_colour_manual(values = c("darkorange", "cornflowerblue"))+
  labs(title="Prediction from mixed-effect model",color='Test.Time') + theme_bw()+   theme(legend.title = element_blank(), axis.title.y = element_text(size=20),plot.title = element_text(size=20, face="bold"), axis.text.x = element_text(size=20),axis.text.y = element_text(size=20),legend.text = element_text(size=20), axis.title=element_text(size=20,face="bold"),strip.text = element_text(size = 20), aspect.ratio =1/1)+coord_cartesian(xlim = c(0,8), ylim = c(0,1))+ scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0))


plot2 <- ggplot(probabilities, aes(N_per_list_mean, lure_mean, colour=Test.Time))+geom_point() + geom_smooth(method = "lm", se = TRUE, aes(fill=Test.Time))+ xlab("Mean correct recall per list (Max = 8)") +
    ylab("Mean lure recall probability") +
    scale_colour_manual(values = c("darkorange", "cornflowerblue"))+
    labs(title='Actual data') + theme_bw()+   theme(legend.title = element_blank(), axis.title.y = element_text(size=20),plot.title = element_text(size=20, face="bold"), axis.text.x = element_text(size=20),axis.text.y = element_text(size=20),legend.text = element_text(size=20), axis.title=element_text(size=20,face="bold"),strip.text = element_text(size = 20), aspect.ratio =1/1)+coord_cartesian(xlim = c(0,8), ylim = c(0,1))+ scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0))
  
grid.arrange(plot1, plot2, ncol=2)

invisible(dev.off())

}


```

```{r semanticdistance}

if (processdata==1){

osfproject <- osf_retrieve_node("9pdyf")
osffiles <- osf_ls_files(osfproject,path='Stage 2/Data/Semantic distance (exploratory analysis)/')
if (!file.exists('data/ukwac_cbow.rda')){
  hid <- pmatch('ukwac_cbow.rda',as.character(unlist(osffiles[,1])))
  osf_download(osffiles[hid,], path='data/')
}
  
load('data/ukwac_cbow.rda')  
  
# lure_item <- head(fm$word, 20)
lure_item <- unique(material$lure)

intrusion_only <- subset(fm, intrusion==1)
intrusion_item <- intrusion_only$response

my_list <- vector()
for (i in 1:length(intrusion_item)){
  new_element <- Cosine(lure_item[1], intrusion_item[i], ukwac)
  my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[2], intrusion_item[i], ukwac)
  my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[3], intrusion_item[i], ukwac)
  my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[4], intrusion_item[i], ukwac)
  my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[5], intrusion_item[i], ukwac)
  my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[6], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[7], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[8], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[9], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[10], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[11], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[12], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[13], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[14], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[15], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[16], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[17], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[18], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[19], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  new_element <- Cosine(lure_item[20], intrusion_item[i], ukwac)
   my_list[[length(my_list) + 1]] <- new_element
  }

my_list <- as.data.frame(my_list)
my_list$item <- rep(1:3301, each=20)
closest <- ddply(my_list, .(item), summarise, closest=max(my_list))

intrusion_with_distance <- cbind(intrusion_only, closest)

average_closest <- ddply(intrusion_with_distance, .(Participant.Private.ID, Delay, Test.Time), summarise, meanDistance=mean(closest))

ddply(average_closest, .(Delay, Test.Time), summarise, average=mean(meanDistance, na.rm=T), stdev=sd(meanDistance, na.rm = T))

semantic_ANOVA <- aov(meanDistance~Delay*Test.Time, data=average_closest)
semmeans <- emmeans(semantic_ANOVA, pairwise ~ Test.Time | Delay)

}


```

# Author Note {.unnumbered}

We have no conflict of interest to disclose. Correspondence concerning this article should be addressed to Matthew Mak, Department of Psychology, University of York, Heslington, York, YO10 5DD, United Kingdom; Email: [matthew.mak\@york.ac.uk](matthew.mak\@york.ac.uk)

# Acknowledgements {.unnumbered}

This research was supported by a BA/Leverhulme Small Research Grant (Number: SRG21\\210150) awarded to Matthew Mak and Gareth Gaskell, who were also supported by a grant from the Economic and Social Research Council (ESRC; ES/T008571/1). Aidan Horner was supported by an ESRC grant (ES/R007454/1). The funders have no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. We would like to express our gratitude to members of the SLAM group for their valuable discussions regarding this work, as well as extend our thanks to the four reviewers for providing constructive feedback on this study.

# Open Science Statement {.unnumbered}

All the materials, data, and analysis scripts are publicly available on Open Science Framework (https://osf.io/9pdyf/).

# Abstract {.unnumbered}

Human memory is known to be supported by sleep. However, less is known about the effect of sleep on false memory, where people remember events that never occurred. In the laboratory, false memories are often induced via the Deese-Roediger-McDermott (DRM) paradigm where participants are presented with semantically related words such as nurse, hospital, and sick (studied words). Subsequently, participants are likely to falsely remember that a related lure word such as doctor was presented. Multiple studies have examined whether these false memories are influenced by sleep, with contradictory results. A recent meta-analysis suggests that sleep may increase DRM false memory when short lists are used. We tested this in a registered report (N=`r nrow(total)`) with a 2 (Interval: Immediate vs. 12-hr Delay) $\times$ 2 (Test Time: 9AM vs. 9PM) between-participant DRM experiment, using short DRM lists (N = 8 words/list) and free recall as the memory test. We found that the Sleep and Wake participants were well-matched on the number of total responses, but those in the Sleep group produced fewer intrusions (i.e., words that were neither studied nor lure words), and when this was statistically controlled for, they showed a greater tendency to recall more critical lures as well as more studied items. Our findings support the view that sleep may facilitate gist abstraction and/or spreading activation, alongside strengthening/protecting newly encoded declarative memories.     

**Keywords**: Sleep, False Memory, DRM, Recall, Gist Abstraction, Spreading Activation

# Experiment {.unnumbered}

# Overview

It is possible to index DRM false memory via free recall or recognition (e.g., Stadler et al., 1999). In this experiment, we used free recall only, because recall tends to be more prone to sleep-related memory effects than recognition [@newbury2019a; @berres2021a; @diekelmann2009a; @lipinska2019a]. Our experiment comprised a study and a test phase. In the study phase, a participant encoded 20 short DRM wordlists, with each containing 8 words. Short lists were chosen because Newbury and Monaghan’s [-@newbury2019a] meta-analysis pinpointed a clear sleep effect in these lists. In the test phase, participants recalled the wordlists in a free recall procedure.

Participants were randomly assigned to one of the four groups: AM-control, PM-control, Sleep, or Wake. Those assigned to the control (aka Immediate) groups carried out the test phase immediately after the study phase, with those in the AM group starting at 9AM (± 1hr) and those in the PM group starting at 9PM (± 1hr). No difference in false or veridical recall was expected between these groups, as prior DRM studies (e.g., [@fenn2009a; @monaghan2017a; @payne2009a]) have consistently demonstrated that immediate recall was equivalent between morning and evening. The inclusion of these control groups helped rule out potential circadian effects on encoding and retrieval (and relatedly, monitoring in the Activation/Monitoring Framework). Finally, participants assigned to the Sleep and Wake groups (collectively referred to as the Delay groups) started the test phase approximately 12 hours after the study phase. Those in the Wake group studied the DRM wordlists in the morning (9AM ± 1hr) and completed the test phase in the evening (9PM ± 1hr) on the same day. Those in the Sleep group encoded the wordlists in the evening (9PM ± 1hr) and completed the test phase in the morning (9AM ± 1hr) the next day. 

# Research questions and corresponding predictions

This experiment set out to address a key question:

$\text{\underline{\#1 Does overnight sleep (vs. daytime wakefulness) influence DRM false recall?}}$

Our prediction was based on the meta-analysis by Newbury and Monaghan [-@newbury2019a], who reported that when a study used short lists, sleep consistently increased DRM false memory. We, therefore, predicted a post-sleep (vs. post-wake) increase in DRM false recall, whereas there would be no such difference between the AM- and PM-control groups.

Our study also addressed a peripheral question:

$\text{\underline{\#2 Does overnight sleep (vs. daytime wakefulness) increase veridical recall of the studied list words?}}$

Again, our prediction is based on Newbury and Monaghan [-@newbury2019a], who found that sleep benefits veridical memory in short lists. Our prediction to this question was, therefore that veridical recall would be greater post-sleep than post-wake, whereas there would be no such difference between the AM- and PM-control groups.

# Design

$\text{\underline{\#1 Does overnight sleep (vs. daytime wakefulness) influence DRM false recall?}}$

For this question, the dependent variable was whether a critical lure is recalled or not (i.e., binary). There were two independent variables: Interval (Immediate vs. Delay) and Test Time (9AM vs. 9PM), both of which were manipulated between-participants. In other words, the four groups were coded as in Table \@ref(tab:table1):

``` {r table1}

table1data <- data.frame(matrix(0,nrow=4,ncol=5))

colnames(table1data) <- c('Groups',' ', 'Interval',' ','Test Time')
table1data[,1] <- c('AM-control','PM-control','Sleep','Wake')
table1data[,2] <- c('=','=','=','=')
table1data[,3] <- c('Immediate','Immediate','Delay','Delay')
table1data[,4] <- c('+','+','+','+')
table1data[,5] <- c('9AM','9PM','9AM','9PM')

knitr::kable(table1data, booktabs = T, caption='How the four groups were coded using Interval and Test Time.', align='ccccc') %>%
  row_spec(0,bold=T) %>%
  kable_styling(latex_options='HOLD_position')

```

To address Research Question \#1, we first tested if any difference between the Sleep and Wake groups was significantly different from that between the AM- and PM-control groups (i.e., an interaction between Interval and Test Time). This is important because it allows us to rule out time-of-day effects. Then, we tested for the simple effect of Test Time (9AM vs. 9PM) within the Immediate and Delay groups. If there is (1) a significant Interval x Test Time interaction and (2) a significant Test Time effect within the Delay groups (Sleep > Wake), we will be able conclude that sleep (but not time-of-day) increases false recall.\footnote{Prior studies in the ‘Sleep $\times$ DRM’ literature (e.g., Fenn et al., 2009; Payne et al., 2009) conducted two separate statistical tests, one comparing Sleep vs. Wake, another comparing AM- vs. PM- controls. They then concluded that Sleep had an effect on DRM false memory beyond time-of-day effects when Test Time was significant in the Sleep vs. Wake comparison ($p$ < 0.05) but not in the AM vs. PM comparison ($p$ > 0.05). Unfortunately, however, this is not sufficient (Nieuwenhuis et al., 2011), as “the difference between ‘significant’ and ‘not significant’ is not itself statistically significant” (Gelmam \& Stern, 2006). Therefore, in order to rule out time-of-day effects, one needs to show that Sleep vs. Wake is significantly different from AM vs. PM-control. This can be captured by an Interval $\times$ Test Time interaction.}  

$\text{\underline{\#2 Does overnight sleep (vs. daytime wakefulness) increase veridical recall of the studied list words?}}$

For this research question, the dependent variable was whether a studied list word was recalled or not (i.e., binary). As per Question #1, there were two between-participant manipulations: Interval (Immediate vs. Delay) and Test Time (9AM vs. 9PM). We first tested if there was an interaction between Interval and Test Time. Then, we tested for the simple effect of Test Time within the Immediate and Delay groups. Note that this research question is secondary to the first.

# Target sample size and stopping rules

Our target sample size was 120 participants/group (i.e., 480 participants in total), defined as those who remained in the sample after applying the exclusion criteria outlined in section 9. This sample size gives us >=90% power to detect all the desired effects for our Research Questions (See **Appendix D** for a detailed power analysis).

# Recruitment

## Online recruitment. 
Participants were recruited online via Prolific (https://www.prolific.co/). All participants completed the experiment unsupervised and at a location of their own choosing. We chose online testing, as opposed to lab-based testing, for at least two reasons. First, given the unpredictability of the COVID-19 pandemic, we did not want to risk the possibility of data collection being disrupted. Second, given the time limit on the funding for this work, it would have been logistically difficult to reach the target sample size were the study conducted in person.

One key concern associated with online testing is data quality. This stems from the fact that researchers cannot monitor participants during an online experiment. However, it has been repeatedly demonstrated that as long as appropriate measures are taken (e.g., [@rodd2019a; @curtis2022a]), data quality from online experiments is no different from lab-based experiments (e.g., [@anwyl-irvine2020a; @barnhoorn2015a; @mak2020a; @mak2021b]). Furthermore, two recent online studies using the same experimental design [@ashton2021a; @mak2023a] found clear evidence of a sleep benefit in the classic paired-associate learning paradigm, replicating well-established evidence from lab-based experiments (e.g., [@lo2014a; @plihal1997a]). Importantly, the effect sizes for sleep from these online studies were roughly equivalent to those reported by lab-based studies. Together, these suggest that it is possible to detect sleep-related memory effects in online experiments, as long as the appropriate measures are put in place. These are detailed in the Procedures section (#8) below.

## Recruitment method. 
Following two previous sleep studies conducted via Prolific [@mak2023a; @mak2023b], we put a short survey on the platform to recruit a pool of participants (N = 2296). This survey is available in **Appendix A** and was hosted on Qualtrics. The first half of the survey asked for basic demographic information: gender identity, age, current country of residence, first language, ethnicity, highest education attainment, and history of developmental/sleep disorders (if any). The survey then provided a brief outline of the main study. It stated that if enrolled, participants would be randomly allocated to one of the four groups and that no preferences would be accommodated. Participants then indicated whether they would like to enrol in the main study. Of the 2296 respondents, 1940 expressed interest in taking part, who were then screened for their eligibility (see inclusion criteria below). Those who fitted our inclusion criteria were then randomly allocated to one of the four experimental groups. A private message was sent to each participant, notifying them of their group allocation. In the end, 534 participants completed both the study and test phases. These participants were reimbursed at a rate of ~£9.5/hr. 

# Inclusion criteria

We applied these inclusion criteria to ensure comparability with prior studies (e.g., [@fenn2009a; @mckeon2012a; @payne2009a; @shaw2017a]):

1.	Aged 18-25

2.	Speaks English as (one of) their first language(s)

3.	No known history of any psychiatric (e.g., schizophrenia), developmental (e.g., dyslexia) or sleep (e.g., insomnia) disorders

4.	Currently resides in the UK, indexed by their IP address (since this experiment requires participants to complete each phase at a certain time of day, it is necessary to restrict the location to prevent participants from taking the study in different time zones)

5.	Normal vision or corrected-to-normal vision

6.	Normal hearing

7.	Able to complete the study using a laptop or a desktop PC

8.	Able to complete both the study and test phases

9.	Has an approval rate of >96% on Prolific. This helps ensure that a participant has a tendency to take online studies seriously.

# Materials

Prior studies in the DRM literature typically showed 8 to 15 words per list (e.g., [@fenn2009a; @shaw2017a; @swannell2013a]). Generally, within this range, showing fewer words reduces false recall rates ([@robinson1997a; @swannell2013a]; see also [@alakbarova2021a]). However, showing even fewer words per list (e.g., 3) results in floor or near-floor rates [@robinson1997a]. Given that sleep seems to have a larger effect on false memory when the gist trace or lure is encoded at a medium level during study [@newbury2019a], we opted for 8 words per list.

We  made use of 20 DRM wordlists (see Table \@ref(tab:table2)), taken from Roediger et al. [-@roediger2001a]. Each list contained 8 semantically related words, and as per the standard DRM paradigm, they were arranged in a descending order of associative strength to the critical lures. A participant studied all 20 lists. We note that the original DRM lists by Roediger et al. [-@roediger2001a] were tailored for American participants, and two words (e.g., *trash*, *Mississippi*) were not immediately relatable to people in the UK. We, therefore, changed these words (e.g., *trash* → *rubbish*), as noted in Table \@ref(tab:table2). 

We acknowledge that previous studies in the ‘Sleep $\times$ DRM’ literature typically showed participants 8 to 16 lists (e.g., [@payne2009a; @mckeon2012a]), so our participants studied more wordlists (i.e., 20). However, since we showed relatively few words per list, the total number of studied words was comparable to prior studies (i.e., 160 in the current vs. 96 to 225 in prior studies). Furthermore, an advantage of showing more wordlists is that more critical lures could be recalled (i.e., 20 lists = 20 lures), potentially increasing variability between participants and hence our ability to detect sleep-related effects.  

# Procedures

The procedure of the study is summarised in Figure \@ref(fig:expprocedure). The study was hosted on Gorilla (www.gorilla.sc; [@anwyl-irvine2020a]). A study phase took approximately 11 minutes. Here, participants first gave informed consent, completed a language/attention check, rated their level of sleepiness on the Stanford Sleepiness Scale (SSS; [@hoddes1973a]), and viewed 20 DRM wordlists.

Immediately afterwards, participants in the AM/PM-control groups carried out the test phase. For those in the Delay groups, the test phase took place approximately 12 hours later. Here, both the Immediate and Delay participants rated their level of sleepiness on SSS and completed a short survey concerned with, for example, morningness/eveningness preference (rMEQ; [@adan1991a]) and sleep duration/quality the night before (see **Appendix B** for the full survey). This survey helped determine whether the four groups were matched in terms of time-of-day preference and whether data from a participant needed to be discarded as a result of meeting the exclusion criteria described in section 9. Finally, the test phase concluded with a 10-minute free recall task where participants recalled as many of the words as they could from the previously seen wordlists.

```{r expprocedure, fig.cap="Experimental procedure.", fig.align="center", include=TRUE, echo=FALSE}

knitr::include_graphics('Figures/expprocedure.pdf')

```

## Exposure to the DRM wordlists.

On the instruction page, participants were told that they would see some English words presented one after the other on the computer screen. They were asked to pay close attention to the words because they would be tested on them later on. No specific instruction was given regarding the subsequent test format. 

During presentation, words in each DRM list were presented visually,\footnote{Newbury and Monaghan [@newbury2019a] found no evidence in their meta-analysis that the modality of presentation modulated the effect of sleep. However, in a set of three experiments, Fenn et al. [@fenn2009a] used auditory presentation in one of them and visual in the other two. As far as we are aware, this is the only study in the ‘Sleep $\times$ DRM’ literature that had used both modalities in the same set of experiments. Sleep appeared to have a larger effect on false memory when visual (vs. auditory) presentation was used. Given this, we opted for visual presentation in the current experiment.} in a fixed order and arranged in descending associative strength to the unpresented critical lure (see Table \@ref(tab:table2) for order). Each list began with a fixation for 1 s, followed by the first word in a list. Each word was shown for 1 s, in a lowercase black font (Arial, size 26) on a white background, and separated by a 500-ms interstimulus interval. After presentation of the final word in a list was 5 s of blank screen. List order was randomised, and each list was seen once. 

``` {r table2}

table2data <- data.frame(matrix(0,nrow=22,ncol=3))

table2data[1,] <- c('Critical lure','False recall probability','List items (arranged in the')
table2data[2,] <- c('of each list','(Roediger et al. 2001)','order of presentation in study)')
table2data[3,] <- c('Window','65','door, glass, pane, shade, ledge, sill, house, open')
table2data[4,] <- c('Sleep','61','bed, rest, awake, tired, dream, wake, snooze, blanket')
table2data[5,] <- c('Doctor','60','nurse, sick, lawyer, medicine, health, hospital, dentist, physician')
table2data[6,] <- c('Smell','60','nose, breathe, sniff, aroma, hear, see, nostril, whiff')
table2data[7,] <- c('Chair','54','table, sit, legs, seat, couch, desk, recliner, sofa')
table2data[8,] <- c('Smoke','54','cigarette, puff, blaze, billows, pollution, ashes, cigar, chimney')
table2data[9,] <- c('Sweet','54','sour, candy, sugar, bitter, good, taste, tooth, nice')
table2data[10,] <- c('Rough','53','smooth, bumpy, road, tough, sandpaper, jagged, ready, coarse')
table2data[11,] <- c('Needle','52','thread, pin, eye, sewing, sharp, point, prick, thimble')
table2data[12,] <- c('Rubbish','49','garbage, waste, can, refuse, sewage, bag, junk, trash (Note 1)')
table2data[13,] <- c('Anger','49','mad, fear, hate, rage, temper, fury, ire, wrath')
table2data[14,] <- c('Soft','46','hard, light, pillow, plush, loud, cotton, fur, touch')
table2data[15,] <- c('City','46','town, crowded, state, capital, streets, subway, country, New York')
table2data[16,] <- c('Cup','45','mug, saucer, tea, measuring, coaster, lid, handle, coffee')
table2data[17,] <- c('Cold','44','hot, snow, warm, winter, ice, wet, frigid, chilly')
table2data[18,] <- c('Mountain','42','hill, valley, climb, summit, top, molehill, peak, plain')
table2data[19,] <- c('Slow','42','fast, lethargic, stop, listless, snail, cautious, delay, traffic')
table2data[20,] <- c('River','42','water, stream, lake, Thames (Note 2), boat, tide, swim, flow')
table2data[21,] <- c('Spider','37','web, insect, bug, fright, fly, arachnid, crawl, tarantula')
table2data[22,] <- c('Foot','35','shoe, hand, toe, kick, sandals, soccer, yard, walk')

knitr::kable(table2data, booktabs = T, col.names=NULL, caption='The 20 DRM wordlists to be used.', align='lll') %>%
  row_spec(1:2,bold=T) %>%
  row_spec(3:22,italic=T) %>%
  row_spec(2,hline_after=T) %>%
  kable_styling(latex_options='HOLD_position') %>%
  add_footnote('Note 1. In Roediger et al. (2001), the critical lure for this list was trash, with rubbish being one of the list items. We used rubbish as the critical lure and trash as a list item because the former is the preferred term in British English.',notation='none') %>%
  add_footnote('Note 2. The original word in Roediger et al. was Mississippi. We replaced it with Thames.',notation='none')

```

There was a surprise attention check after the 4$^{th}$, 9$^{th}$, 13$^{th}$, 18$^{th}$ lists, where participants saw an erroneous maths equation such as “3 + 3 = 11”. It was presented for 1 s, in the same font and style as the list words [@thomas2017a]. Immediately afterwards, participants were asked to report what 3 + 3 was according to what was just shown. 

## Free Recall.

Participants had 10 mins to type out all the words they could remember from the study phase in a textbox. When there was 2 min left, a timer appeared. Participants could not proceed before the time was up.

To maximise the likelihood that participants paid full attention instead of doing something else (e.g., playing with their phone) during recall, there was an attention check throughout: On the same page as the response textbox, there was a white square that turned red every 2 to 3 mins. The change in colour lasted for 10 s, during which a single digit was shown. Participants had to enter the digit into a separate textbox to show that they were paying attention. Throughout the 10-min recall task, the square turned red four times, so participants needed to enter four digits as they attempted the recall task.

## Additional measures to ensure data quality. 

At the start of the study phase, participants were encouraged to take the experiment seriously and were informed that their participation would contribute to science. After rating their level of sleepiness, participants must pass a language/attention check. This involved the auditory presentation of a short story. Replay and pausing were not permitted. Participants then answered two simple comprehension questions based on the story. Failure to answer both questions correctly led to their data being excluded from further analysis. These questions helped to ensure that participants could indeed understand English and were in a reasonably quiet environment. Next, to prevent participants from multitasking on the computer, both the study and test phases required participants to enter full-screen mode. Participants were told that exit from full-screen mode during the study may lead to no payment. This was made possible by Gorilla, which recorded the browser’s and the monitor’s sizes. At the end of the study phase, participants were asked to describe how they learnt the words in a sentence. Participants who said they wrote down or similarly recorded the words were excluded from further analysis.

# Exclusion criteria 

Exclusion was applied on the participant level. A participant’s dataset was excluded from further analysis and replaced, if

1.	they exited full-screen mode in any of the phases.

2.	they failed the language/attention check at the start of the study.

3.	they reported to have written down or recorded the wordlists during the study phase.

4.	(*Sleep and Wake groups only*) they reported consuming any alcoholic drinks between study and test.

5.	(*Sleep group only*) they reported to have had fewer than 6 hours of overnight sleep prior to test or rated their sleep quality as poor or extremely poor.

6.	(*Wake group only*) they reported to have had a nap between study and test.

7.	they failed more than one of the four attention checks (i.e., 3 + 3 = 11) at study.

8.	they failed to report more than one of the four digits in the attention check of free recall.

9.	they submitted a blank response in free recall.

10.	 (this criterion was removed; see Deviations from Stage-1 registered report on p. 1 for explanation)

11.	their completion time for either the study or test phase is 3 standard deviations above or below their respective mean completion time of the first 480 participants who completed the study.

# Participants

Of the `r length(unique(raw_fm$Participant.Private.ID))` participants who completed both the study and test phases, `r length(unique(raw_fm$Participant.Private.ID))-length(unique(fm$Participant.Private.ID))` were excluded for meeting one or more of the exclusion criteria. The full list of excluded participants and their respective reason for exclusion is available on OSF (see exclusion_OSF.csv). Our final sample size comprised `r length(unique(fm$Participant.Private.ID))` participants, with 124 in each of the Immediate groups, and 120 in each of the Delay groups. Group characteristics are summarised in Table \@ref(tab:table3). 

``` {r table3}

table3data <- data.frame(matrix(0,nrow=11,ncol=5))

table3data[1,] <- c('Characteristics','Immediate','Immediate','Sleep (aka','Wake (aka')
table3data[2,] <- c('','-AM','-PM','Delay-AM)','Delay-PM)')
table3data[3,] <- c('N before exclusion','130','127','135','143')
table3data[4,] <- c('N after exclusion','124','124','120','120')
table3data[5,] <- c('Mean age (SD)','22.24 (2.18)','22.34 (2.03)','22.18 (1.93)','22.25 (1.93)')
table3data[6,] <- c('Gender (Female:Male:Other)','64 : 54 : 2','77 : 46 : 1','62 : 57 : 1','58 : 61 : 1')
table3data[7,] <- c('% participants identified as ethnically white','78.2%','73.4%','81.7%','80%')
table3data[8,] <- c('Mean SSS rating at study (SD)','2.58 (0.98)','2.64 (1.12)','2.66 (0.96)','2.58 (0.98)')
table3data[9,] <- c('Mean SSS rating at test (SD)','2.73 (1.04)','2.95 (1.29)','2.63 (1.21)','2.67 (1.18)')
table3data[10,] <- c('Mean rMEQ score (SD)','15.89 (1.67)','15.59 (1.91)','15.72 (1.83)','15.53 (1.99)')
table3data[11,] <- c('Mean N of intervening hr between study and test (SD)','NA','NA','12.22 (0.74)','12.14 (0.81)')

knitr::kable(table3data, booktabs = T, col.names=NULL, caption='Group characteristics.', align='lcccc') %>%
  row_spec(2,hline_after=T) %>%
  kable_styling(latex_options='HOLD_position', font_size=9) %>%
  add_footnote('Notes. (1) SSS stands for Stanford Sleepiness Scale and ranges from 1 to 6, with higher values indicating greater sleepiness. (2) rMEQ stands for reduced Morningness/Eveningness Questionnaire; it ranges from 1 to 25, with higher values indicating greater morningness preference.',notation='none')

```

Prior to the confirmatory analyses, we first checked if the four groups were matched on their morningness/eveningness preference and degree of sleepiness at study/test (as indexed by the Stanford Sleepiness Scale). These are summarised in Table \@ref(tab:table3). We compared the four groups on each of the measures using one-way ANOVAs, which showed no significant differences (SSS at study: F = 0.21, p = .888; SSS at test: F = 1.63, p = .183; rMEQ: F = 0.97, p = .408). We also compared the Sleep and Wake groups on the number of intervening hours between study and test using a between-participant t-test, which revealed no significant difference [t(236.16) = 0.86, p = .389]. In sum, our four groups were well-matched on these potentially confounding factors.

# Data pre-processing

The free recall data were pre-processed. The first step was to remove any duplicate responses. The second was to correct all obvious spelling and typing errors to the nearest English words, defined as Levenstein distance $\leq$ 2 (e.g., **cigerette* → *cigarette*).\footnote{If a misspelt response has more than one nearest word, the response was considered as an intrusion.} Responses with added or dropped inflectional suffixes (i.e., *-s*, *-ed*, *-ing*, adjectival *-er*) were corrected. Responses with derivational changes were considered as intrusions. For instance, one of the studied words is *pollution*; if a participant recalled *pollutions*, the plural suffix was dropped; however, if a participant recalled *pollutant*, this was considered as an intrusion. 

# Results of Pre-registered Analyses

Following prior studies in the ‘Sleep $\times$ DRM’ literature, we adopted a frequentist approach for all our analyses. The alpha level was set at 0.05. 

## Positive control.

We checked if our paradigm consistently elicited the well-established DRM effect across participants. Given free recall, the chance level of a critical lure being produced is 0. We submitted the number of critical lures produced by all participants (Range: 0 to 20) to a one-sample t-test, with the chance level being 0.  It showed that participants were susceptible to false recall [t(`r lurettest$parameter`) = `r round(lurettest$statistic, digits = 2)`, `r format.pval(lurettest$p.value, digits = 3, eps = .001)`], providing evidence for the classic DRM false memory effect.

## Control analysis.

Payne et al. [-@payne2009a] found that participants falsely recalled more critical lures post-sleep (vs. post-wake). However, it is possible that participants simply had a greater tendency to put down more unseen words after sleep, not because sleep increases DRM false recall per se. Therefore, before addressing our key research questions, we checked if participants across groups were comparable in terms of their bias in producing unseen items. In Payne et al. [-@payne2009a], this bias was indexed via the number of intrusions (i.e., neither the studied nor the lure items), which was roughly equivalent between their Sleep and Wake groups [M$_{Sleep}$ = 5.6 vs. M$_{Wake}$ = 6.2; p = .60] as well as between their AM and PM-control groups [MAM = 4.1 vs. MPM = 4.1; p = .99]. To check if this is the case in our data, we used a 2 (Interval: Immediate vs. Delay) $\times$ 2 (Test Time: AM vs. PM) Poisson regression. We chose Poisson regression, as opposed to ANOVA, because the intrusion data were count data, meaning that data distribution were right-skewed and hence unsuitable for ANOVA. Figure \@ref(fig:intrusionfig) summarises the number of intrusions in each group. 

```{r intrusionfig, fig.cap="Number of intrusions produced, summarised across the four groups. Each dot represents an individual participant, and the error bars represent 95\\% confidence intervals.", fig.align="center", include=TRUE, echo=FALSE}

knitr::include_graphics('Figures/intrusiongraph.pdf')

```

A 2 $\times$ 2 Poisson regression revealed significant effects of Interval ($\beta$ = `r round(int_pois_sum$coefficients[2,1], digits = 3)`, SE = `r round(int_pois_sum$coefficients[2,2], digits = 3)`, z = `r round(int_pois_sum$coefficients[2,3], digits = 3)`, p < `r format.pval(int_pois_sum$coefficients[2,4], digits = 3, eps = .001)`) and Test Time ($\beta$ = `r round(int_pois_sum$coefficients[3,1], digits = 3)`, SE = `r round(int_pois_sum$coefficients[3,2], digits = 3)`, z = `r round(int_pois_sum$coefficients[3,3], digits = 3)`, p <  `r format.pval(int_pois_sum$coefficients[3,4], digits = 3, eps = .001)`), which were qualified by a significant interaction ($\beta$ = `r round(int_pois_sum$coefficients[4,1], digits = 3)`, SE =  `r round(int_pois_sum$coefficients[4,2], digits = 3)`, z = `r round(int_pois_sum$coefficients[4,3], digits = 3)`, p = `r round(int_pois_sum$coefficients[4,4], digits = 3)`). Given this, we tested the simple effects of Test Time within the Immediate and Delay groups using the emmeans package [@lenth2021a]. Within the Immediate groups, the evening participants (M = `r round(intrusion_CI[2,4], digits = 2)`; SD = `r round(intrusion_CI[2,5], digits = 2)`) produced more intrusions than the morning participants (M = `r round(intrusion_CI[1,4], digits = 2)`; SD = `r round(intrusion_CI[1,5], digits = 2)`) (z = `r round(int_sum$contrasts$z.ratio[1], digits = 3)`, p = `r format.pval(int_sum$contrasts$p.value[1], digits = 3, eps = .001)`). Likewise, in the Delay groups, the Wake participants, who completed free recall in the evening (M = `r round(intrusion_CI[4,4], digits = 2)`; SD = `r round(intrusion_CI[4,5], digits = 2)`), produced more intrusions than the Sleep participants, who completed recall in the morning (M = `r round(intrusion_CI[3,4], digits = 2)`; SD = `r round(intrusion_CI[3,5], digits = 2)`) (z = `r round(int_sum$contrasts$z.ratio[2], digits = 3)`, p = `r format.pval(int_sum$contrasts$p.value[2], digits = 3, eps = .001)`). Together, our data indicate that participants who attempted free recall in the evening (vs. morning) were more prone to intrusions, and this effect was greater in the Delay than in the Immediate groups. These unexpected findings prompted us to explore whether *the number of total responses* (i.e., studied + lures + intrusions) differed between morning and evening test time. Interestingly, this exploratory analysis (see section 13.1) showed no effect of Test Time. Together, these suggest that attempting free recall in the evening led to a selective increase in intrusions, but not necessarily a global increase in output bias. Finally, given that Test Time had a significant effect on intrusions, we followed our pre-registered analysis plan by adding the number of intrusions as a numeric covariate in the 2 $\times$ 2 mixed-effects models below. 

## Confirmatory analysis 1.

This analysis addresses our key research question:

$\text{\underline{\#1 Does overnight sleep (vs. daytime wakefulness) influence DRM false recall?}}$

The number of critical lures falsely recalled is summarised across groups in Figure \@ref(fig:lurefig).

```{r lurefig, fig.cap="Number of critical lures falsely recalled, summarised across the four groups. Each dot represents an individual participant, and the error bars represent 95\\% confidence intervals.", fig.align="center", include=TRUE, echo=FALSE}

knitr::include_graphics('Figures/luregraph.pdf')

```

A generalised linear mixed-effect model (GLMM) was fitted to the critical lure data on the item level (N of observations = `r nrow(lure_pp)` participants $\times$ 20 critical lures).\footnote{The use of GLMM is a clear departure from prior ‘Sleep $\times$ DRM’ studies, the majority of which addressed the same research question using an independent t-test or ANOVA (e.g., Diekelmann et al., 2010; Monaghan et al., 2017; Payne et al., 2009). We explained in Appendix C why these statistical tests are usually not appropriate in the context of DRM recall and why GLMM are more advantageous.}  The dependent variable was binary: whether a critical lure was recalled or not (1 vs. 0). The fixed effects were the number of intrusions a participant produced, Interval (Immediate vs. Delay), Test Time (AM vs. PM), and an Interval by Test Time interaction. Interval and Test Time were coded using sum contrasts [@barr2019a]. The random-effect structure was determined by the “buildmer” package [@voeten2021a], which automatically found the maximal model that was capable of converging using backward elimination (with the “bobyqa” optimiser). This means that model selection started from the maximal model, as justified by the experimental design [@barr2013a]. The model we reported and based our interpretation on was the most maximal model that was capable of converging (see the upper half of Table \@ref(tab:table4) for the final random-effect structure and model output). 

``` {r table4}

lmout <- summary(lure_model)$coefficients
smout <- summary(studied_model)$coefficients

temp <- capture.output(lure_pairwise$contrasts[1])
emout1 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))
temp <- capture.output(lure_pairwise$contrasts[2])
emout2 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))
temp <- capture.output(studiedem1$contrasts[1])
emout3 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))
temp <- capture.output(studiedem1$contrasts[2])
emout4 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))

temp <- capture.output(prem$contrasts[1])
emout5 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))
temp <- capture.output(prem$contrasts[2])
emout6 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))

luress <- subset(lure_pp, lure_pp$Delay=='12-hour delay')
meanout1 <- mean(luress$Lure.Recalled[which(luress$Test.Time=='AM')])
meanout2 <- mean(luress$Lure.Recalled[which(luress$Test.Time=='PM')])
sdout1 <- sd(luress$Lure.Recalled[which(luress$Test.Time=='AM')])
sdout2 <- sd(luress$Lure.Recalled[which(luress$Test.Time=='PM')])

table4adata <- data.frame(matrix(0,nrow=6,ncol=5))
table4bdata <- data.frame(matrix(0,nrow=6,ncol=5))

table4adata[1,] <- c('','Estimate','SE','z','p')
table4adata[2,] <- c('Intercept',round(lmout[1,1:3],digits=3),p_mark_significant(p_format(lmout[1,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4adata[3,] <- c('Intrusions',round(lmout[4,1:3],digits=3),p_mark_significant(p_format(lmout[4,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4adata[4,] <- c('Interval (Immediate vs. Delay)',round(lmout[2,1:3],digits=3),p_mark_significant(p_format(lmout[2,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4adata[5,] <- c('Test Time (AM vs. PM)',round(lmout[3,1:3],digits=3),p_mark_significant(p_format(lmout[3,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4adata[6,] <- c('Interval x Test Time',round(lmout[5,1:3],digits=3),p_mark_significant(p_format(lmout[5,4],digits=2,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

table4bdata[1,] <- c('','Estimate','SE','z','p')
table4bdata[2,] <- c('Intercept',round(smout[1,1:3],digits=3),p_mark_significant(p_format(smout[1,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4bdata[3,] <- c('Intrusions',round(smout[4,1:3],digits=3),p_mark_significant(p_format(smout[4,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4bdata[4,] <- c('Interval (Immediate vs. Delay)',round(smout[2,1:3],digits=3),p_mark_significant(p_format(smout[2,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4bdata[5,] <- c('Test Time (AM vs. PM)',round(smout[3,1:3],digits=3),p_mark_significant(p_format(smout[3,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))
table4bdata[6,] <- c('Interval x Test Time',round(smout[5,1:3],digits=3),p_mark_significant(p_format(smout[5,4],digits=2,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

knitr::kable(table4adata, booktabs = T, col.names = NULL, caption='Outputs from confirmatory generalised mixed-effect models examining the effects of Intrusions, Interval, and Test Time in false and veridical recall.', align='lllll') %>%
  kableExtra::add_header_above(c('Random-effect structure: (Intrusions | Participant.ID) + (1 | Lure)'=5),align='l') %>%
  kableExtra::add_header_above(c('False (lure) recall'=5),bold=T,align='c') %>%
  row_spec(1,italic=T) %>%
  kable_styling(latex_options='HOLD_position')

knitr::kable(table4bdata, booktabs = T, col.names = NULL, align='lllll') %>%
  kableExtra::add_header_above(c('Random-effect structure: (Intrusions | Participant.ID) + (Interval | Studied.Item)'=5),align='l') %>%
  kableExtra::add_header_above(c('Veridical (studied word) recall'=5),bold=T,align='c') %>%
  row_spec(1,italic=T) %>%
  kable_styling(latex_options='HOLD_position')

```

The number of intrusions had a significant effect on lure recall, such that participants who produced more intrusions tended to recall more critical lures (z = `r round(lmout[4,3],digits=3)`, p < `r p_format(lmout[4,4],accuracy=0.001,digits=3,leading.zero=F)`). There were no main effects of Interval or Test Time (zs < 0.95, ps > .34), but there was a significant Interval by Test Time interaction (z = `r round(lmout[5,3],digits=3)`, p = `r p_format(lmout[5,4],accuracy=0.001,digits=2,leading.zero=F)`). Following our pre-registered analysis plan, we proceeded to test the simple effects of Test Time within the Immediate and Delay groups, using the emmeans package [@lenth2021a] in R. Among the Immediate groups, there was no significant difference in lure recall between the AM-control and PM-control participants ($\beta$ = `r emout1[6]`, SE = `r emout1[7]`, z = `r emout1[9]`, p = `r p_format(as.numeric(emout1[10]),leading.zero=F,digits=3)`). However, among the Delay groups, there was a significant difference ($\beta$ = `r emout2[7]`, SE = `r emout2[8]`, z = `r round(as.numeric(emout2[10]),digits=2)`, p = `r p_format(as.numeric(emout2[11]),leading.zero=F,digits=2)`) such that the Sleep participants (M = `r round(meanout1,digits=2)`, SD = `r round(sdout1,digits=2)`) reported more critical lures than the Wake participants (M = `r round(meanout2,digits=2)`, SD = `r round(sdout2,digits=2)`).

## Box 1 {.unnumbered}

*R codes for Confirmatory Analysis 1*

```{r box1, include=TRUE, eval=FALSE, echo=TRUE}

contrasts(FalseRecall$Interval) <- contr.sum(2)  #sum contrast for interval
contrasts(FalseRecall$Test_Time) <- contr.sum(2) #sum contrast for test time
library(lme4) 
library(buildmer) 
# 2 x 2 GLMM
FalseRecallModel <- buildmer(Recalled ~ Interval * Test_Time + (1 | Participant) + 
                    (Interval * Test_Time | Item), data = FalseRecall, family = 
                    "binomial",buildmerControl = buildmerControl(direction='backward', 
                    args = list(control=glmerControl(optimizer="bobyqa"))))
# Obtain the simple-effects of Test Test within the Immediate and Delay groups
library(emmeans)
emmeans(FalseRecallModel, pairwise ~ Test_Time | Interval)

```

## Confirmatory analysis 2.	 
This analysis addresses the secondary question:

$\text{\underline{\#2 Does overnight sleep (vs. daytime wakefulness) increase veridical recall of the studied list words?}}$

Figure \@ref(fig:studiedfig) summarises the number of studied list words correctly recalled across groups.

```{r studiedfig, fig.cap="Number of studied list words correctly recalled, summarised across the four groups. Each dot represents an individual participant, and the error bars represent 95\\% confidence intervals.", fig.align="center", include=TRUE, echo=FALSE}

knitr::include_graphics('Figures/studiedgraph.pdf')

```

We fitted a GLMM to the veridical recall dataset (N of observations = 488 participants $\times$ 160 studied words). The dependent variable was whether a studied word was recalled or not. The fixed effects were the the number of intrusions a participant produced, Interval (Immediate vs. Delay), Test Time (AM vs. PM), and an Interval by Test Time interaction. The coding scheme and computation procedure were the same as in the previous analysis. The model output and its random-effect structure are available in the lower half of Table \@ref(tab:table4). There were no significant effects of intrusions (z = `r table4bdata[3,4]`, p = `r table4bdata[3,5]`) or Test Time (z = `r table4bdata[5,4]`, p = `r table4bdata[5,5]`). However, there was a main effect of Interval (z = `r table4bdata[4,4]`, p `r p_format(smout[2,4],digits=3,accuracy=0.001,leading.zero=FALSE)`) such that participants in the Delay groups recalled significantly fewer studied words (M = `r round(mean(studied_delpp$Studied.Recalled),digits=2)`, SD = `r round(sd(studied_delpp$Studied.Recalled),digits=2)`) than those in the Immediate groups (M = `r round(mean(studied_impp$Studied.Recalled),digits=2)`, SD = `r round(sd(studied_impp$Studied.Recalled),digits=2)`), indicating time-dependent memory decay. Importantly, there was a significant Interval by Test Time interaction (z = `r table4bdata[6,4]`, p `r p_format(smout[5,4],digits=2,accuracy=0.001,leading.zero=FALSE)`), so we broke it down with the emmeans package as pre-registered. Within the Immediate groups, the evening participants (M = `r round(studied_CI[2,4],digits=2)`, SD = `r round(studied_CI[2,5],digits=2)`) recalled more studied words than the morning participants (M = `r round(studied_CI[1,4],digits=2)`, SD = `r round(studied_CI[1,5],digits=2)`), although this was not statistically significant ($\beta$ = `r emout3[6]`, SE = `r emout3[7]`, z = `r round(as.numeric(emout3[9]),digits=2)`, p = `r p_format(as.numeric(emout3[10]),leading.zero=F,digits=2)`). Within the Delay groups, there was a main effect of Test Time ($\beta$ = `r emout4[7]`, SE = `r emout4[8]`, z = `r round(as.numeric(emout4[10]),digits=3)`, p = `r p_format(as.numeric(emout4[11]),leading.zero=F,digits=1)`), such that the Sleep participants (M = `r round(studied_CI[3,4],digits=2)`, SD = `r round(studied_CI[3,5],digits=2)`) outperformed their Wake counterparts (M = `r round(studied_CI[4,4],digits=2)`, SD = `r round(studied_CI[4,5],digits=2)`). Together, these support the well-established findings that sleep is typically beneficial to the retention of newly encoded declarative memories.

### Complementary Bayesian analysis

Although our inference was based on a frequentist approach, we pre-registered to use a Bayesian analysis to complement and test the strength of our results.

Bayes Factors were computed for (1) the Interval $\times$ Test Time interaction in the false and veridical mixed-effect models above, and for the simple effects of Test Time within the (2) Immediate and (3) Delay groups. Following the procedures in Gilbert et al. [@gilbert2018a], a Bayes Factor was computed using the Bayesian Information Criterion (BIC) approximation from two competing GLMMs. For instance, in computing the Bayes Factor for the Interval $\times$ Test Time interaction, two models were needed: An alternative model containing the full fixed-effects structure (Intrusions + Interval + Test Time + Interval $\times$ Test Time), and a null model lacking the interaction.\footnote{To obtain the Bayes Factor for the simple effects of Test Time, the alternative model will contain Test Time as the sole fixed effect while the null model will contain no fixed effects.} To estimate the Bayes Factor, we used the formula $e^{\Delta BIC_{10}/2}$, where $\Delta BIC_{10}$ is the BIC for the null model minus the BIC for the alternative model [@masson2011a; @lindelov2018a; @wagenmakers2007a]. This produces a Bayes Factor$_{10}$, which was interpreted with reference to Lee and Wagenmakers’ [-@lee2014a] heuristics. The current BIC approximation method has the advantage of being a straightforward solution for mixed-effects models; however, its usage remains controversial as it is known to favour the simpler model (i.e., the null hypothesis; [@lindelov2018a; @vandekerckhove2014a; @weakliem1999a]). Table \@ref(tab:table5) summarises the Bayes Factors derived from our mixed-effects models.

``` {r table5}

table5data <- data.frame(matrix(0,nrow=8,ncol=2))

colnames(table5data) <- c('Effects','Bayes Factor 10')
table5data[,1] <- c('False (lure) recall','Interval x Test Time','Test Time in Immediate groups','Test Time in Delay groups','Veridical (studied word) recall','Interval x Test Time','Test Time in Immediate groups','Test Time in Delay groups')
table5data[c(1,5),2] <- ''
table5data[2,2] <- round(lureBF,digits=5)
table5data[3,2] <- round(lureimmediateBF,digits=5)
table5data[4,2] <- round(luredelayBF,digits=5)
table5data[6,2] <- round(studiedBF)
table5data[7,2] <- round(studimBF,digits=5)
table5data[8,2] <- round(studdelayBF,digits=5)

knitr::kable(table5data, booktabs = T, caption='Bayes Factors for the Interval x Test Time interactions and the simple effects of Test Time in the lure and veridical recall data.', align='ll') %>%
  row_spec(c(1,5),italic=T) %>%
  kable_styling(latex_options='HOLD_position')

```

Surprisingly, all the Bayes Factors, except for the Interval $\times$ Test Time interaction in the studied word model, were below 0.1. These, according to Lee and Wagenmakers [-@lee2014a], can be taken as extreme evidence for the null hypotheses. In other words, there is a discrepancy between our frequentist and Bayesian analyses. We stress that this Bayesian analysis is complementary in nature and our primary test of significance remains the frequentist test.  

# Results of Exploratory Analyses

In this section, we present the results of four exploratory analyses, which explored (1) the number of total responses (i.e., studied + lure + intrusions) across groups, (2) whether the effect of sleep on lure recall is modulated by veridical recall, as suggested by Diekelmann et al. [@diekelmann2010a], (3) the extent to which a lure being produced is predicted by its corresponding list items being recalled, and (4) the semantic distance between intrusions and critical lures.

## Number of total responses

In light of the finding that participants who completed free recall in the evening (vs. morning) produced more intrusions, we asked whether this was driven by these participants having a greater tendency to put down more responses generally. To test this, we calculated the number of total responses by each participant (i.e., studied + lures + intrusions), which is summarised across groups in Figure \@ref(fig:totalfig). 

```{r totalfig, fig.cap="Number of total responses (i.e., studied + lure + intrusions), summarised across the four groups. Each dot represents an individual participant, and the error bars represent 95\\% confidence intervals.", fig.align="center", include=TRUE, echo=FALSE}

knitr::include_graphics('Figures/totalgraph.pdf')

```

Unlike the intrusion data which had an overall mean of `r round(mean(intrusions$intrusions),digits=1)` and a minimum of `r min(intrusions$intrusions)`, the number of total responses had a mean of `r round(mean(total$total),digits=1)` and a minimum of `r min(total$total)`, suggesting that it is better to consider total responses as continuous, as opposed to count, data. As such, we used a 2 $\times$ 2 between-participant ANOVA to test for the effects of Interval and Test Time on the number of total responses, which was log-transformed to give a more normal distribution. The ANOVA revealed a main effect of Interval [F(`r summary(total_anova)[[1]][[1]][1]`, `r summary(total_anova)[[1]][[1]][4]`) = `r round(summary(total_anova)[[1]][[4]][1],digits=2)`, p `r p_format(summary(total_anova)[[1]][[5]][1],digits=2,accuracy=0.001,leading.zero=F)`], such that participants in the Immediate groups (M = `r round(mean(total$total[which(total$Delay=='Immediate/Control')]),digits=1)`, SD = `r round(sd(total$total[which(total$Delay=='Immediate/Control')]),digits=1)`) gave more responses than those in the Delay groups (M = `r round(mean(total$total[which(total$Delay=='12-hour delay')]),digits=1)`, SD = `r round(sd(total$total[which(total$Delay=='12-hour delay')]),digits=1)`). This pattern is consistent with the confirmatory analysis on the studied list words. However, importantly, there was no significant effect of Test Time [F(`r summary(total_anova)[[1]][[1]][2]`, `r summary(total_anova)[[1]][[1]][4]`) = `r round(summary(total_anova)[[1]][[4]][2],digits=2)`, p = `r p_format(summary(total_anova)[[1]][[5]][2],digits=3,accuracy=0.001,leading.zero=F)`], and the Interval by Test Time interaction was also non-significant [F(`r summary(total_anova)[[1]][[1]][3]`, `r summary(total_anova)[[1]][[1]][4]`) = `r round(summary(total_anova)[[1]][[4]][3],digits=2)`, p = `r p_format(summary(total_anova)[[1]][[5]][3],digits=3,accuracy=0.001,leading.zero=F)`]. Together with the intrusion data, this exploratory analysis suggests that attempting free recall in the evening led to a selective increase in intrusions but not necessarily an increase in general response bias.

## Is the effect of sleep on false recall modulated by veridical memory?

In 36 participants (18 Sleep and 18 Wake), Diekelmann et al. [-@diekelmann2010a] found that the effect of sleep on DRM false recall was modulated by veridical recall. In their analysis, they performed a post-hoc median split on adjusted veridical recall (i.e., correct recall minus intrusions), separating their participants as either high or low performers. They reported that participants in the Sleep (vs. Wake) group falsely recalled more lures, but only if they were low performers. This finding, as far as we can see, has yet to be replicated, so we explored whether it could be observed in our data, which is more well-suited to test for individual differences given our large sample size.

In this exploratory analysis, we followed Diekelmann et al. [-@diekelmann2010a] by focusing on the Delay groups\footnote{Note that Diekelmann et al. (2010) did not have Immediate/Control groups.} and by performing a median split on our sample’s adjusted veridical recall (Median = 5), classifying our participants as either high (>5; N = 117) or low ($\leq$ 5; N = 123) performers. We followed the analysis approach of Diekelmann et al. [-@diekelmann2010a], but since the number of critical lures a participant produced is count data, we used a 2 (Group: Sleep vs. Wake) $\times$ 2 (Adjusted veridical recall: High vs. Low Performers) Poisson regression, instead of an ANOVA. This analysis showed no main effect of Group ($\beta$ = `r round(as.numeric(emout5[7]),digits=3)`, z = `r round(as.numeric(emout5[10]),digits=3)`, p = `r p_format(as.numeric(emout5[11]),digits=3,leading.zero=F)`) but a main effect of Adjusted veridical recall ($\beta$ = -0.438, z = -3.766, p < .001), such that high performers (M = `r round(premmeans[1,3],digits=2)`, SD = `r round(premmeans[1,4],digits=2)`) tended to falsely recall more critical lures than low performers (M = `r round(premmeans[2,3],digits=2)`, SD = `r round(premmeans[2,4],digits=2)`) ([@thapar2001a; @toglia1999a], but see [@cann2011a; @roediger2001a; @stadler1999a]). Furthermore, importantly, the interaction between Group and Adjusted veridical recall was not significant ($\beta$ = `r round(prsum$coefficients[4,1],digits=3)`, z = `r round(prsum$coefficients[4,3],digits=3)`, p = `r p_format(prsum$coefficients[4,4],digits=3,leading.zero=F)`). Despite this, we followed Diekelmann et al. [-@diekelmann2010a] by comparing low performers in the Sleep and Wake groups. Contrary to their findings, emmeans showed that our low performers in both groups recalled essentially the same number of critical lures (M$_{Sleep}$ = `r round(premmeans[2,3],digits=2)`, SD$_{Sleep}$ = `r round(premmeans[2,4],digits=2)` vs. M$_{Wake}$ = `r round(premmeans[4,3],digits=2)`, SD$_{Wake}$ = `r round(premmeans[4,4],digits=2)`; $\beta$ = `r round(as.numeric(emout6[7]),digits=3)`, z = `r round(as.numeric(emout6[10]),digits=3)`, p = `r p_format(as.numeric(emout6[11]),digits=3,leading.zero=F)`). In other words, this exploratory analysis found no evidence that the effect of sleep on false recall was modulated by veridical memory, casting doubt over the robustness and reliability of Diekelmann et al.’s [-@diekelmann2010a] findings.

## The relationship between lure and veridical recall on a list level

Here, we asked whether recall probability of a lure (e.g., *doctor*) is predicted by the number of corresponding list items being recalled (e.g., *nurse*, *hospital*, *sick*), and if it does, whether it differs between the Sleep and Wake groups. These questions help shed light on the degree to which sleep increases lure recall via processes such as retrieval-induced generalisation\footnote{Retrieval-induced generalisation: Retrieval of one word cueing retrieval of a related word (e.g., Berens \& Bird, 2017)} or gist abstraction\footnote{Gist abstraction: Extraction of the central or essential meaning of learned information}, as these processes may predict a different degree of interdependence between lure and veridical recall. If sleep (vs. wake) promoted retrieval-induced generalisation, lure and veridical recall should become more strongly correlated with each other after sleep, because better veridical recall for a set of studied words may generalise to the corresponding critical lure (or vice versa). On the other hand, if sleep (vs. wake) promoted gist abstraction, lure recall may become less related to memories for the corresponding list items, because theories of gist abstraction such as iOtA may predict that sleep would selectively boost the overlapping gist memory (i.e., the lure) but not necessarily the specific studied words. 

In this exploratory analysis, we first calculated a participant’s number of correct recalls per DRM wordlist (Range = 0 - 8) and used this to predict recall of the corresponding critical lure in a generalised mixed-effect model, which had Number of intrusions, Number of correct recall per list, Interval (Immediate vs. Delay), Test Time (AM vs. PM), and an interaction of the latter three as the fixed effects. Interval and Test Time were effect coded, and the random-effect structures contained a by-participant intercept only, as prescribed by the buildmer package. The model output is summarised in Table \@ref(tab:table6). 

``` {r table6}

modout <- summary(iota_buildmer000)$coefficients

table6data <- data.frame(matrix(0,nrow=9,ncol=5))
colnames(table6data) <- c('Fixed effects','Estimate','SE','z','p')

table6data[1,] <- c('Intercept', round(modout[1,1:3],digits=3),p_format(modout[1,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[2,] <- c('Intrusions', round(modout[5,1:3],digits=3),p_format(modout[5,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[3,] <- c('Correct recall/list', round(modout[4,1:3],digits=3),p_format(modout[4,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[4,] <- c('Test Time', round(modout[3,1:3],digits=3),p_format(modout[3,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[5,] <- c('Interval', round(modout[2,1:3],digits=3),p_format(modout[2,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[6,] <- c('Correct recall/list x Test Time', round(modout[8,1:3],digits=3),p_format(modout[8,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[7,] <- c('Correct recall/list x Interval', round(modout[7,1:3],digits=3),p_format(modout[7,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[8,] <- c('Interval x Test Time', round(modout[6,1:3],digits=3),p_format(modout[6,4],digits=3,accuracy=0.001,leading.zero=FALSE))
table6data[9,] <- c('Correct recall/list x Interval x Test Time', round(modout[9,1:3],digits=3),p_format(modout[9,4],digits=3,accuracy=0.001,leading.zero=FALSE))


knitr::kable(table6data, booktabs = T, caption='Outputs from the exploratory generalised mixed-effect model examining the effects of intrusions, correct recall per list, Interval (Immediate vs. Delay), and Test Time (Sleep vs. Wake) in false recall.', align='lllll') %>%
  row_spec(0, bold=T) %>%
  kable_styling(latex_options='HOLD_position')

```

Given the significant three-way interaction, we broke it down by computing two additional GLMMs, one within the Immediate and another within the Delay group. These models had Number of intrusions, Number of correct recall per list, Test Time (AM vs. PM), and an interaction of the latter two as the fixed effects. Table \@ref(tab:table7) summarises the model outputs.

``` {r table7}

modout1 <- summary(iota_buildmer3_standard)$coefficients
modout2 <- summary(iota_buildmer2)$coefficients

table7data <- data.frame(matrix(0,nrow=5,ncol=9))
colnames(table7data) <- c('Fixed effects','Estimate','SE','z','p','Estimate','SE','z','p')

table7data[1,] <- c('Intercept', round(modout1[1,1:3],digits=3), p_mark_significant(p_format(modout1[1,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)),round(modout2[1,1:3],digits=3), p_mark_significant(p_format(modout2[1,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

table7data[2,] <- c('Intrusions', round(modout1[4,1:3],digits=3), p_mark_significant(p_format(modout1[4,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)),round(modout2[4,1:3],digits=3), p_mark_significant(p_format(modout2[4,4],digits=1,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

table7data[3,] <- c('Correct recall/list', round(modout1[3,1:3],digits=3), p_mark_significant(p_format(modout1[3,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)),round(modout2[3,1:3],digits=3), p_mark_significant(p_format(modout2[3,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

table7data[4,] <- c('Test Time', round(modout1[2,1:3],digits=3), p_mark_significant(p_format(modout1[2,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)),round(modout2[2,1:3],digits=3), p_mark_significant(p_format(modout2[2,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

table7data[5,] <- c('Correct recall/list x Test Time', round(modout1[5,1:3],digits=3), p_mark_significant(p_format(modout1[5,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)),round(modout2[5,1:3],digits=3), p_mark_significant(p_format(modout2[5,4],digits=3,accuracy=0.001,leading.zero=FALSE),symbols=c('*',''),cutpoints=c(0,0.05,1)))

knitr::kable(table7data, booktabs = T, caption='Outputs from the exploratory generalised mixed effect models examining the effects of Intrusions, Correct recall per list, and Test Time (Sleep vs. Wake) in false recall.', align='lllllllll') %>%
  row_spec(0, bold=T) %>%
  kableExtra::add_header_above(c('','Immediate'=4,'Delay'=4),bold=T,align='c') %>%
  kable_styling(latex_options='HOLD_position')


```

Across the Immediate and Delay groups, the number of intrusions and correct recall per list both had a main effect (ps $\leq$ .001) such that they were positively correlated with lure recall. However, the effect of Test Time was not significant in either group (ps > .11). Finally, for the Correct recall per list $\times$ Test Time interaction, it was significant in the Delay (z = `r round(modout2[5,3],digits=3)`, p `r p_format(modout2[5,4],digits=3,accuracy=0.001,leading.zero=F)`) but not the Immediate groups (z = `r round(modout1[5,3],digits=3)`, p = `r p_format(modout1[5,4],digits=3,accuracy=0.001,leading.zero=F)`). To interpret the former, we used the R package, effects [@fox2019a], to visualise it (see Figure \@ref(fig:delayfig)A) and plotted lure recall probability against veridical recall on a participant level (see Figure \@ref(fig:delayfig)B).

```{r delayfig, fig.cap="(A) Prediction from generalised mixed-effect model on the combined effects of correct recall/list and group (sleep vs. wake) on false recall (B) Correlation between mean lure and studied word recall in the Sleep and Wake groups. Each dot represents an individual participant. Dotted lines/shaded areas represent 95\\% confidence intervals.", fig.align="center", include=TRUE, echo=FALSE}

knitr::include_graphics('Figures/delaygraph.pdf')

```

In line with the previous exploratory analysis on adjusted veridical recall, we found that when a participant recalled more studied items from a DRM wordlist, they were also more likely to recall the corresponding critical lure, suggesting some kind of retrieval-induced generalisation; importantly, however, this effect was weaker in the Sleep than the Wake participants. This finding is striking, especially in light of our confirmatory findings that overall, the Sleep participants produced more critical lures (with intrusions controlled for) and more studied list items than the Wake participants. What this exploratory analysis suggests is that after sleep (vs. wakefulness), whether a lure was recalled may be less reliant on the retrieval of its corresponding studied items, potentially hinting that sleep may affect DRM false memory primarily via some kinds of gist abstraction process.

## Semantic distance between intrusions and critical lures

As per the DRM literature, responses that were neither the studied list words nor the critical lures were classified as (non-critical) intrusions. For instance, our participants studied *nurse*, *sick*, *lawyer*, *medicine*, *health*, *hospital*, *dentist*, and *physician*, with *doctor* as the critical lure. Responses such as *clinic* and *coconut* would both be considered intrusions, but clearly, *clinic* is semantically more related to the studied list words than *coconut*. In other words, there is much diversity within the intrusion data. Here, we explored whether our four groups differed in terms of the semantic distance between intrusions and critical lures, as indexed by pre-trained semantic spaces (ukWaC; [@baroni2009a]) derived from word2vec [@guenther2015a]. We reasoned that since lure recall was greater in our Sleep (vs. Wake) participants, the intrusions produced by these participants could be more related to the lures in semantic space (e.g., @mak2023a). To test this, we computed the cosine similarities between each intrusion and each of the 20 critical lures (see Table \@ref(tab:table8) for an illustration). The intrusion-lure pair with the highest cosine similarity (i.e., the nearest neighbour) was used for this analysis. 

``` {r table8}

table8data <- data.frame(matrix(0,nrow=6,ncol=4))
table8data[1,]  <- c('Participant ID','Intrusion produced','Lure','cosine')
table8data[2,]  <- c('','by a participant','','')
table8data[3,] <- c('1','ear','smell','0.405')
table8data[4,] <- c('1','ear','sleep','0.302')
table8data[5,] <- c('1','ear','doctor','0.239')
table8data[6,] <- c('1','ear','window','0.129')

knitr::kable(table8data, booktabs = T, col.names=NULL, caption='Procedure for the exploratory analysis on semantic distance between intrusion and lure.', align='llll') %>%
  row_spec(1:2, bold=T) %>%
  row_spec(2, hline_after=T) %>%
  kable_styling(latex_options='HOLD_position')


table8bdata <- data.frame(matrix(0,nrow=8,ncol=6))
table8bdata[1,] <- c('Participant ID','Intrusion produced','Closest lure','cosine','Number of intrusion','Average cosine/')
table8bdata[2,] <- c('','by a participant','','','produced','participant')
table8bdata[3,] <- c('1','ear','smell','0.405','','')
table8bdata[4,] <- c('1','metro','city','0.351','4','0.347')
table8bdata[5,] <- c('1','heavy','slow','0.413','','')
table8bdata[6,] <- c('1','clear','slow','0.219','','')
table8bdata[7,] <- c('2','clinic','doctor','0.494','','')
table8bdata[8,] <- c('2','beach','mountain','0.484','2','0.489')

knitr::kable(table8bdata, booktabs = T, col.names=NULL, align='llllcc') %>%
  row_spec(1:2, bold=T) %>%
  row_spec(c(2,6), hline_after=T) %>%
  kable_styling(latex_options='HOLD_position',font_size=8)

```


``` {r extractsemdist}

aovresults <- unlist(summary(semantic_ANOVA))
temp <- capture.output(semmeans$contrasts[2])
emout7 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))

sdmeans <- ddply(average_closest, .(Delay, Test.Time), summarise, average=mean(meanDistance, na.rm=T), stdev=sd(meanDistance, na.rm = T))

```

Since the number of intrusions produced varies greatly between participants, we averaged the lure-intrusion cosine on a participant level and used this as the dependent variable. A 2 (Interval) $\times$ 2 (Test Time) between-participant ANOVA revealed no effects of Interval (z = `r round(aovresults[13],digits=3)`, p = `r p_format(aovresults[17],digits=3,accuracy=0.001,leading.zero=F)`) or Test Time (z = `r round(aovresults[14],digits=3)`, p = `r p_format(aovresults[18],digits=3,accuracy=0.001,leading.zero=F)`), and their interaction was also non-significant (z = `r round(aovresults[15],digits=3)`, p = `r p_format(aovresults[19],digits=3,accuracy=0.001,leading.zero=F)`). We explored further by comparing the cosine in the Sleep and Wake groups. While this comparison is in the predicted direction (M$_{Sleep}$ = `r round(sdmeans[3,3],digits=3)`, SD$_{Sleep}$ = `r round(sdmeans[3,4],digits=3)` vs. M$_{Wake}$ = `r round(sdmeans[4,3],digits=3)`, SD$_{Wake}$ = `r round(sdmeans[4,4],digits=3)`), it was not statistically significant according to an emmeans pairwise comparison (z = `r emout7[9]`, p = `r p_format(as.numeric(emout7[10]),digits=3,accuracy=0.001,leading.zero=F)`). We interpret these null findings as suggesting that the effect of sleep in the DRM paradigm may be fairly restricted to the lures/studied list words. 

## Results summary

In light of the extensive dataset and the comprehensive analyses conducted, we decided to summarise our key findings in Table \@ref(tab:table9) to help readers gain a better understanding of the overall picture.

``` {r table9}

table9data <- data.frame(matrix(0,nrow=11,ncol=6))

table9data[1,] <- c('Categories','Interval x','Mean in the','Mean in the','Pairwise','Interpretation')
table9data[2,] <- c('','Test Time','Sleep group','Wake group','comparison','')
table9data[3,] <- c('','p<.05?*','(SD)','(SD)','p<.05?','')

table9data[4,] <- c('Intrusions','Yes',paste0(round(intrusion_CI[3,4], digits = 2),' (',round(intrusion_CI[3,5], digits = 2),')'),paste0(round(intrusion_CI[4,4], digits = 2),' (',round(intrusion_CI[4,5], digits = 2),')'),'Yes','Few intrusions')
table9data[5,] <- c('','','','','','after sleep')

table9data[6,] <- c('Critical lures','Yes (N of intrusions',paste0(round(meanout1, digits = 2),' (',round(sdout1, digits = 2),')'),paste0(round(meanout2, digits = 2),' (',round(sdout2, digits = 2),')'),'Yes','Greater DRM false')
table9data[7,] <- c('(Max=20)','included as a coviariate)','','','','recall after sleep')

table9data[8,] <- c('Studied list words','Yes (N of intrusions',paste0(round(studied_CI[3,4], digits = 2),' (',round(studied_CI[3,5], digits = 2),')'),paste0(round(studied_CI[4,4], digits = 2),' (',round(studied_CI[4,5], digits = 2),')'),'Yes','Greater veridical recall')
table9data[9,] <- c('(Max=160)','included as a coviariate)','','','','after sleep')

table9data[10,] <- c('Total responses','No',paste0(round(totalstats[3,3], digits = 2),' (',round(totalstats[3,4], digits = 2),')'),paste0(round(totalstats[4,3], digits = 2),' (',round(totalstats[4,4], digits = 2),')'),'No','Sleep and Wake groups')
table9data[11,] <- c('','','','','','were well-matched')

knitr::kable(table9data, booktabs = T, col.names=NULL, caption='Summary of the key findings.', align='llllll') %>%
  row_spec(1:3, bold=T) %>%
  row_spec(c(3,5,7,9), hline_after=T) %>%
  kable_styling(latex_options='HOLD_position',font_size=8) %>%
  add_footnote('* A significant Interval x Test Time interaction suggests that any difference between the Sleep and Wake groups cannot',notation='none') %>%
  add_footnote('be solely explained by study/test being completed at different time of day.',notation='none')

```

# Time-of-day effects on intrusions

Rather unexpectedly, and contrary to the null findings from prior ‘Sleep $\times$ DRM’ studies (e.g., [@payne2009a; @mckeon2012a]), participants who completed free recall in the evening (i.e., the PM-control and Wake groups) produced more intrusions than those in the morning (i.e., the AM-control and Sleep groups). Notably, Test Time did not have a significant effect on the number of total responses, suggesting that completing free recall in the evening (vs. morning) led to a selective increase in intrusions but not a global output bias. Also worth noting is that our four groups were well-matched on their circadian preference (see rMEQ scores in Table \@ref(tab:table3)), suggesting that the effect of Test Time on intrusions is unlikely to be attributable to free recall being completed at optimal or non-optimal times of day, which are known to affect performance on some cognitive tasks (e.g., [@hasher2002a; @krishnan2015a; @may2005a]). As to why evening (vs. morning) testing led to a selective increase in intrusions, we propose that it might be due to accumulation of information throughout the day. 

Participants tested in the evening would have engaged in various daytime activities in the preceding 10-12 hours, while those tested in the morning would have been sleeping for the majority of those hours. In other words, participants tested in the evening would have accumulated a large amount of sensory and linguistic information, which might interfere or even compete with memories for the studied list words at retrieval, increasing the likelihood of intrusions being produced. In contrast, for participants in the AM-control and Sleep groups, not only would they have less accumulated sensory input from the preceding hours, but they may also benefit from one of the proposed functions of sleep, which is to “reset” the brain by pruning (relatively unimportant) information accumulated prior to sleep [@tononi2006a; @tononi2014a]. As such, it seems reasonable to infer that participants tested in the evening (vs. morning) may have experienced more interference from information accumulated throughout the course of the day, which may have, in turn, led to an increase in intrusions at retrieval. This interpretation also fits with the finding that Test Time had a greater effect in the Delay (Wake > Sleep) than in the Immediate groups (PM > AM). Participants in the Wake groups attempted recall after 12 hours of daytime wakefulness, so interference from accumulated sensory input is likely to impede not only retrieval, but also memory storage throughout the 12-hour interval. In contrast, participants in the PM-control group attempted recall shortly after study, so interference from accumulated information is likely to be mostly restricted to memory retrieval. In other words, interference from accumulated sensory input is expected to be greater in the Wake than in the PM-control group, which was in fact the case.

Finally, having considered the potential reason why evening testing may increase intrusions, we turn to why no previous ‘Sleep $\times$ DRM’ studies had reported the same. We argue that this is because prior studies were underpowered. In our intrusion data, the effect size of Test Time was small: An exploratory comparison of the AM vs. PM groups using a Mann-Whitney U test revealed an effect size of Pearson’s r = -0.096 (which roughly corresponds to Cohen’s d = 0.193), while the same test on the Sleep vs. Wake groups revealed an effect size of r = 0.175 (d = 0.355). In order to detect the latter at 80% power (assuming alpha = 0.05) in a two-tailed between-participant Mann-Whitney U-test, a total sample size of 264 participants is required (G*Power; [@faul2009a]), which is substantially greater than the sample sizes of the vast majority of existing memory/sleep studies (e.g., [@payne2009a; @yaremenko2021a]). As such, it is not surprising that few prior sleep studies had reported time-of-day effects in declarative memories. 

# Some reflections 

**Mixed evidence in the existing literature**.	Our well-powered registered report had a total sample size of `r nrow(total)`, with 120 in each of the Sleep and Wake groups. This far surpasses the sample sizes of prior ‘Sleep $\times$ DRM’ studies, where the median N was 27.6 per group. In our data, the effect of sleep on lure recall was only significant when controlling for differences in intrusion rates, and we checked the size of this sleep effect in an exploratory analysis, putting the estimate at Cohen’s d = 0.274.\footnote{We used the eff\_size function in the emmeans package to estimate the effect size of Test Time (sleep vs. wake) in our confirmatory GLM model, with sigma = sigma(lure\_model) and edf = infinite.} This estimate is substantially lower than that from Newbury and Monaghan’s [-@newbury2019a] meta-analysis, which reported to be Cohen’s d = +0.92 (95% CI: 0.54, 1.30). The larger sample size and well-powered nature of our registered report contribute to a more precise estimation of the effect size, highlighting the need for cautious interpretation of prior evidence and the possibility that prior effect sizes may have been inflated due to, for example, publication bias and small sample sizes. Furthermore, given sleep had such a small effect on DRM false memory, it is perhaps not surprising that previous studies had produced mixed evidence. In light of these, we echo the view of a recent article [@cordi2021a] that future sleep research must prioritise robust methodologies (e.g., registered report and pre-registration) and larger sample sizes to enhance the reliability and generalisability of sleep-related memory effects [see also @nemeth2019a].

# References {.unnumbered}

<div id="refs"></div>


# Appendix A: Screening Survey {.unnumbered}

``` {r sstable}

sstabledata <- data.frame(matrix(0,nrow=29,ncol=1))

sstabledata[1,1] <- 'Page 1: Demographic information'

sstabledata[2,1] <- '1)	What is your gender identity?'
sstabledata[3,1] <- '2)	How old are you?'
sstabledata[4,1] <- '3)	In what country do you currently live?'
sstabledata[5,1] <- '4)	What is your first language(s)? '
sstabledata[6,1] <- '5)	What is your ethnicity?'
sstabledata[7,1] <- '6)	What is the highest level of education you have completed?'
sstabledata[8,1] <- '7)	Do you have any history of any psychiatric (e.g., schizophrenia), developmental'
sstabledata[9,1] <- '(e.g., autism, dyslexia), or sleep disorders (e.g., insomnia)? '
sstabledata[10,1] <- '8)	If your answer to the above is Yes, please can you name the diagnosis/es?'

sstabledata[11,1] <- 'Page 2: Outline of the main study'

sstabledata[12,1] <- 'IMPORTANT: Please read carefully'
sstabledata[13,1] <- 'We are recruiting hundreds of participants for a simple memory study. We would'
sstabledata[14,1] <- 'like to see if you may be interested in taking part.'
sstabledata[15,1] <- 'In Task 1, participants will see and remember some English words. This will take about 10 mins.'
sstabledata[16,1] <- 'In Task 2, participants will complete a simple memory test based on the words they saw in Task 1.'
sstabledata[17,1] <- 'This requires about 12 mins.'
sstabledata[18,1] <- 'Participants will receive £3.5 (£9.5/hour) upon completion of the two tasks. '
sstabledata[19,1] <- 'Importantly, participants will be randomly allocated to one of the four groups:'
sstabledata[20,1] <- 'Group A (AM Group): You can start Task 1 and 2 any time between 8.30-10.30AM.'
sstabledata[21,1] <- 'Group B (PM Group): You can start Task 1 and 2 any time between 8.30-10.30PM.'
sstabledata[22,1] <- 'Group C (Delay Group 1): You can start Task 1 any time between 8.30-10.30AM and then Task 2'
sstabledata[23,1] <- 'between 8.30-10.30PM on the same day. '
sstabledata[24,1] <- 'Group D (Delay Group 2): You can start Session 1 any time between 8.30-10.30PM and then Task 2'
sstabledata[25,1] <- 'between 8.30-10.30AM the day after.'
sstabledata[26,1] <- 'Those in Groups C and D will receive a £0.2 bonus upon completion of the study. Unfortunately,'
sstabledata[27,1] <- 'we are NOT able to accommodate any preferences for group allocation.'
sstabledata[28,1] <- 'If you are happy to take part in our memory study, press Yes below. If not, press No.'
sstabledata[29,1] <- 'Yes / No'

knitr::kable(sstabledata, booktabs = T, col.names=NULL, align='l') %>%
  row_spec(c(1,11), align='c') %>%
  row_spec(c(1,10,11), hline_after=T) %>%
  row_spec(12, bold=T) %>%
  kable_styling(latex_options='HOLD_position')

```

# Appendix B: Survey in the test phase {.unnumbered}

1.	(Sleep group only) Approximately what time did you go to bed last night?

2.	(Sleep group only) Approximately what time did you wake up this morning?

3.	(Sleep group only) How would you rate the quality of last night's sleep?
**Very Good, Good, Fair, Poor, Very Poor**

4.	(Wake group only) Did you have a nap between Session 1 and now?
**Yes, No**

5.	(Wake group only) If your answer to the above is Yes, how long was the nap?

6.	Did you consume any alcoholic drinks in the last 12 hours? If Yes, how much?
Yes, No

7.	Did you consume any caffeinated drink in the last 6 hours? If Yes, how much?
Yes, No

8.	How many people are in close proximity (< 3 meter) to you RIGHT NOW? 

9.	How bright is your immediate environment RIGHT NOW?
**Too bright, Sufficiently bright, A bit dark, Very dark**

10.	How noisy is the environment you are in RIGHT NOW? 
**Very quiet, Quiet, Noisy, Very noisy.**

**The following questions were taken from the reduced version of the Morningness/Evenningess questionnaire (Adan & Almirrall, 1991).**

11.	Approximately what time would you get up if you were entirely free to plan your day?
**5am-6:30am, 6:30am-7:45am, 7:45am-9:45am, 9:45am-11am, 11am-12 noon**

12.	On a regular day, during the first half hour after you wake up in the morning, how do you feel?
**Very tired, Fairly tired, Fairly refreshed, Very refreshed**

13.	On a regular day, at approximately what time in the evening do you feel tired, and, as a result, in need of sleep?
**8-9pm, 9-10:15pm, 10:15pm-12:45am, 12:45-2am, 2-3am**

14.	On a regular day, at approximately what time of day do you usually feel your best?
**5-8am, 8-10am, 10am-5pm, 5-10pm, 10pm-5am**

15.	One hears about "morning types" and "evening types." Which one of these types do you consider yourself to be?
**Definitely an evening type, Rather more an evening type than a morning type, Rather more a morning type than an evening type, Definitely a morning type**


# Appendix C: Justifications for using GLMM for false recall (as opposed to t-test/ANOVA) {.unnumbered}

The number of critical lures falsely recalled by a participant is count data, ranging from 0 to anything from 8 to 20 (depending on how many DRM lists were shown). In Payne et al. [-@payne2009a] for instance, the mean number of lure recalls was ~3.25 (out of 8). Count data with a low mean almost never approximates a normal distribution, because it is truncated at 0 (i.e., negative scores are impossible) and is skewed to the right [@herbison-a]. Parametric tests like t-test and ANOVA assume a normal distribution, so they are unlikely to be suitable for false recall data. GLMM, on the other hand, does not assume normal distribution [@lo2015a]. In addition, GLMM has numerous advantages over a t-test or an ANOVA; for instance, it can take by-participant and by-item variance into account, giving researchers the ability to test whether the effect of an independent variable generalises across participants and items [e.g., @brysbaert2018a]. 

# Appendix D: Power analysis {.unnumbered}

\beginsupplement

```{r powersetup, echo=FALSE, include=FALSE}

fabricated <- read.csv('data/Fabricated_FalseRecall_Data.csv')

## Descriptive statistics 
### within the delay groups
#subset (delay groups only)
delay_only <- subset(fabricated, Interval=="Delay")

#mean per participant
delay_only_pp <- ddply(delay_only, .(participant, Test_Time), summarise, lure_recalled=sum(correct), lure_recalled_percent=(sum(correct)/20)*100)

#t test comparing sleep vs. wake
powert1 <- t.test(lure_recalled~Test_Time, data=delay_only_pp) #p < 0.001

#effect size between sleep and wake
powerd1 <- cohen.d(lure_recalled~Test_Time, data=delay_only_pp) #d = 0.54

#mean for sleep and wake
delay_only_group_level <- ddply(delay_only_pp, .(Test_Time), summarise, average_lure_percent=mean(lure_recalled_percent), stdev_lure_percent=sd(lure_recalled_percent))

### Within the immediate groups

#subset (immediate groups only)
immediate_only <- subset(fabricated, Interval=="Immediate")

#mean per participant
immediate_only_pp <- ddply(immediate_only, .(participant, Test_Time), summarise, lure_recalled=sum(correct), lure_recalled_percent=(sum(correct)/20)*100)

#t test comparing AM vs. PM control
powert2 <- t.test(lure_recalled~Test_Time, data=immediate_only_pp) #p = 0.708

#effect size between AM and PM control
powerd2 <- cohen.d(lure_recalled~Test_Time, data=immediate_only_pp) #d = -0.05

#mean and SD for AM and PM control
delay_only_group_level <- ddply(immediate_only_pp, .(Test_Time), summarise, average_lure_percent=mean(lure_recalled_percent), stdev_lure_percent=sd(lure_recalled_percent))

## Compute 2 (Interval) x 2 (Test Time) generalised linear mixed-effect model

#contrast coding
fabricated$Test_Time <- as.factor(fabricated$Test_Time)
contrasts(fabricated$Test_Time) <- contr.sum(2)
fabricated$Interval <- as.factor(fabricated$Interval)
contrasts(fabricated$Interval) <- contr.sum(2)

#build GLMM using buildmer, which automatically finds the maximal model that is capable of converging
fabricated_model <- buildmer(correct~Interval*Test_Time+(1|participant)+(Interval*Test_Time|item), data=fabricated, family="binomial",buildmerControl = buildmerControl(direction='order', args = list(control=glmerControl(optimizer="bobyqa")))) 
#fabricated_model has a by-participant intercept only.

#This is just to compute the same thing again with lmer so that we can run power analysis using simr, which is not compatible with buildmer.
fabricated_model <- glmer(correct~Interval*Test_Time+(1|participant), data=fabricated, family="binomial", control=glmerControl(optimizer="bobyqa"))

#fixed-effect estimates in Table 3
fmout <- summary(fabricated_model)

if (processdata==1){

fixef(fabricated_model)["Interval1:Test_Time1"] <- 0.076
set.seed(99)
psout <- powerSim(fabricated_model, fixed("Interval1:Test_Time1"), nsim=500, progress=FALSE)

### Simple effect of sleep vs. wake
#compute GLMM within the delay groups
fabricated_simple_model <- glmer(correct~Test_Time+(1|participant), data=delay_only, family="binomial", control=glmerControl(optimizer="bobyqa"))

#fixed effects estimate from the model above
summary(fabricated_simple_model)

#beta for Test Time = 0.139
fixef(fabricated_simple_model)["Test_TimePM"] <- 0.139

# Run simulation
set.seed(99)
psout2 <- powerSim(fabricated_simple_model,fixed("Test_TimePM"),nsim=500)

save(file='data/processeddata.RData',list=c('intrusion_poisson','intrusionout','intrusion_CI','lure_model_buildmer','lure_model','lure_pairwise','lureeffects','lure_model_without_covariate_buildmer','null_lure','lureBF','lure_delay_model1','lure_immediate_model1','lure_delay_model1_null','lure_immediate_model1_null','luredelayBF','lureimmediateBF','lurettest','studied_model_buildmer','studied_model','studiedem1','studiedem2','studiedBF','studied_delay_model1','studied_delay_model1_null','studdelayBF','studied_immediate_model1','studied_immediate_model1_null','studimBF','prem','prsum','iota_buildmer000','iota_buildmer2','iota_buildmer2_standard','iota_buildmer3_standard','my_list','closest','average_closest','semantic_ANOVA','semmeans','my_list','psout','psout2'))

}

temp <- capture.output(psout)
pstext <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))

temp <- capture.output(psout2)
pstext2 <- unlist(strsplit(gsub("([*]+$)|[<]", "", temp[2]), "\\s+"))


```

According to Newbury and Monaghan’s [-@newbury2019a] meta-analysis, the effect size for sleep in DRM false memory is Hedge’s g = +0.92 (95% CI: 0.54, 1.30; p < .001) in short lists (10 words per list).\footnote{Hedge’s g and Cohen’s d are interchangeable when the sample size is larger than 30 (Kline, 2004; Lakens, 2013).} However, due to certain biases in the psychology literature (e.g., publication bias), it has been argued that published effect sizes are generally inflated [e.g., @schaefer2019a] and that power analysis should be based on the lowest meaningful estimate [@albers2018a; @cortex2013a]. Therefore, we opted for a more conservative (yet contextualised) effect size estimate and went for the lower-bound of the 95% confidence interval reported by Newbury and Monaghan [-@newbury2019a], which is g = +0.54.

On estimating power in GLMM, a recent guideline [@kumle2021a] recommends using well-powered data from previous experiments. However, as far as we are aware, no prior ‘Sleep $\times$ DRM’ studies have made their data publicly available. We, therefore, simulated a dataset for our power calculation (available on OSF).

The first step is to determine a sample size. We have the financial resources to reach up to 160 participants/group (i.e., 640 in total), so we began by fabricating a dataset containing 120 participants/group. We made up 20 false recall observations for each participant. We then split the dataset by Interval, so one dataset for the Delay (Sleep + Wake) groups, another for the Immediate (AM + PM-control) groups, with each containing 4800 observations from 240 participants. In the first dataset, we simulated the false recall data for the Delay groups such that they approximated the data distribution [M$_{Sleep}$ = 45.9% (SD = 20.6%) vs M$_{Wake}$ = 36.3% (SD = 21.2%), p = .005] from a prior study (Payne et al., [-@payne2009a]; Experiment 1). Then, the data were manipulated to fit with our effect size assumption, such that the effect size for sleep is d = +`r round(powerd1$estimate,digits=2)` [M$_{Sleep}$ = 44.7% (SD = 12.6%) vs. M$_{Wake}$ = 38.0% (SD = 12.0%); t(`r round(powert1$parameter,digits=1)`) = `r round(powert1$statistic,digits=2)`, p = `r p_format(powert1$p.value,leading.zero=F,digits=3,accuracy=0.001)`]. Afterwards, we simulated the false recall data in the second dataset for the AM and PM-control groups such that they also approximated the data distribution in Payne et al. [-@payne2009a] (Experiment 1; MAM = 42.5% (SD = 19.6%) vs. MPM = 46.3% (SD = 23.5%), p = .57) and that they did not differ significantly from each other [MAM = 42.9% (SD = 13.0%) vs. MPM= 43.5% (SD = 14%); t(`r round(powert2$parameter,digits=1)`) = `r round(powert2$statistic,digits=2)`, p = `r p_format(powert2$p.value,leading.zero=F,digits=3,accuracy=0.001)`, d = `r round(powerd2$estimate,digits=2)`].\footnote{Notably, the standard deviations (SDs) from Payne et al. (2009; Experiment 1) are larger than those in our fabricated datasets. This is because Payne et al. showed only 8 wordlists (i.e., maximum lure recall = 8) while ours will show 20 (i.e., maximum lure recall = 20). To explain why this matters, a more concrete example here is useful: In Payne et al, a participant falsely recalling 3 lures would have a false recall rate of 37.5\% while another recalling 4 lures would have a rate of 50\%. So there is a 12.5\% difference between each successive number. In our fabricated data, recalling 3 lures has a false recall rate of 15\% while 4 lures has a rate of 20\%, so there is a 5\% difference. Therefore, understandably, the SDs in our fabricated datasets are necessarily lower than theirs (by roughly a half).} 

We then merged the two fabricated datasets together and fitted a GLMM to it, using the lme4 package [@bates2015a]. The dependent variable, fixed effects structure, coding scheme, and computation procedures were identical to those described in section 12.3. Table \@ref(tab:tableD1) shows the fixed-effects estimates from the converged model, which has a by-participant intercept only.

``` {r tableD1}

modout <- summary(fabricated_model)$coefficients

tableD1data <- data.frame(matrix(0,nrow=4,ncol=5))
colnames(tableD1data) <- c('Fixed effects','Estimate','SE','z','p')

tableD1data[1,] <- c('Intercept', round(modout[1,1:3],digits=3),p_format(modout[1,4],digits=3,accuracy=0.001,leading.zero=FALSE))
tableD1data[2,] <- c('Interval', round(modout[2,1:3],digits=3),p_format(modout[2,4],digits=3,accuracy=0.001,leading.zero=FALSE))
tableD1data[3,] <- c('Test Time', round(modout[3,1:3],digits=3),p_format(modout[3,4],digits=1,accuracy=0.001,leading.zero=FALSE))
tableD1data[4,] <- c('Interval x Test Time', round(modout[4,1:3],digits=3),p_format(modout[4,4],digits=1,accuracy=0.001,leading.zero=FALSE))


knitr::kable(tableD1data, booktabs = T, caption='Fixed-effects estimates from the converged maximal model examining the effects of Interval and Test Time in the fabricated dataset.', align='lllll') %>%
  row_spec(0, bold=T) %>%
  kable_styling(latex_options='HOLD_position')

```

Based on the fixed-effects estimates, we estimated the power a sample size of 480 (i.e., 120/group) has for detecting an Interval and Test Time interaction. We conducted Monte Carlo simulation using the “simr” package [@green2016a] in R (see Box 2 for R codes). After 500 simulations, it was estimated that a sample of this size gives `r round(100*psout$x/psout$n,digits=1)`% power (95% CI: `r parse_number(pstext[3])`, `r parse_number(pstext[4])`) to detect a significant interaction. Then, we estimated the power we have for detecting a simple effect of Test Time within the Delay groups (i.e., Sleep vs. Wake). Following the simulation procedures above, it was estimated that 120 participants/group (i.e., 240 in the Delay groups) will give about `r round(100*psout2$x/psout2$n,digits=1)`% power (95% CI: `r parse_number(pstext2[3])`, `r parse_number(pstext2[4])`). In sum, our power calculation showed that having 120 participants/groups will give ample power (>90%) to detect both an Interval x Test Time interaction and a simple effect of Sleep vs. Wake. Finally, we also estimated that we will have at least 80% power as long as we have >99 participants/group. Therefore, in case we fail to reach our target sample size of 120 participants/group before funding expires but manage to recruit >99/group, our proposed experiment will still have satisfactory power.

We note that the focus of our proposed experiment is Research Question #1 [Does sleep (vs. wakefulness) influence DRM false recall?], so we based our power analysis on this question. Despite this, the estimate of 120 participants/group will also give over 90% power to detect the desired effects for Research Question #2 [Does sleep (vs. wake) increase veridical recall?], assuming the effect size for sleep is similar between Questions #1 and #2. Furthermore, since there are more studied list words than critical lures (160 vs. 20), the GLMM for addressing Question #2 will have substantially more observations than that for Question #1 (~76800 vs. ~9600), boosting power on the item level. In short, our target sample size of 120 participants/group will give us sufficient power for both Research Questions.

## Box 2 {.unnumbered}

*R codes for Monte Carlo simulation*

```{r box2, include=TRUE, eval=FALSE, echo=TRUE}

library(simr)
fixef(fabricated_model)["Interval1:Test_Time1"] <- 0.076
set.seed(99)
powerSim(fabricated_model, fixed("Interval1:Test_Time1"), nsim=500)

```

```{r box2b, include=TRUE, eval=TRUE, echo=FALSE}

psout

```
